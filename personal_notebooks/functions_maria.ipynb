{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions María"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "cities_df = pd.read_csv('../data/california_cities.csv')\n",
    "inmo_df = pd.read_csv('../data/ejemplo_housing.csv')\n",
    "flights_df = pd.read_csv('../data/dataset_viajes_jun23.csv')\n",
    "customers_df = pd.read_csv('../data/Marketing-Customer-Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values and cardinality (percentage of unique values).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values and cardinality for each column of the input DataFrame.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    }).T\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_extra(df, count = False): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values, cardinality (percentage of unique values), and optionally, the count of non-null values.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    count : bool, optional\n",
    "        If True, includes the count of non-null values in each column (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values, cardinality, and optionally, the count of non-null values for each column.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    })\n",
    "    \n",
    "    # Optionally add the count of non-null values and rearrange the columns\n",
    "    if count:\n",
    "        not_null_count = df.notna().sum()\n",
    "        df_summary.insert(1, 'NOT-NULL COUNT', not_null_count)\n",
    "\n",
    "    return df_summary.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE        int64  int64  object  float64  int64  int64  float64   \n",
       "MISSINGS (%)       0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES        2      3       2       88      7      7      248   \n",
       "CARDIN (%)        0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "              embarked   class     who adult_male    deck embark_town   alive  \\\n",
       "DATA_TYPE       object  object  object       bool  object      object  object   \n",
       "MISSINGS (%)      0.22     0.0     0.0        0.0   77.22        0.22     0.0   \n",
       "UNIQUE_VALUES        3       3       3          2       7           3       2   \n",
       "CARDIN (%)        0.34    0.34    0.34       0.22    0.79        0.34    0.22   \n",
       "\n",
       "              alone  \n",
       "DATA_TYPE      bool  \n",
       "MISSINGS (%)    0.0  \n",
       "UNIQUE_VALUES     2  \n",
       "CARDIN (%)     0.22  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT-NULL COUNT</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE         int64  int64  object  float64  int64  int64  float64   \n",
       "NOT-NULL COUNT      891    891     891      714    891    891      891   \n",
       "MISSINGS (%)        0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES         2      3       2       88      7      7      248   \n",
       "CARDIN (%)         0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "               embarked   class     who adult_male    deck embark_town  \\\n",
       "DATA_TYPE        object  object  object       bool  object      object   \n",
       "NOT-NULL COUNT      889     891     891        891     203         889   \n",
       "MISSINGS (%)       0.22     0.0     0.0        0.0   77.22        0.22   \n",
       "UNIQUE_VALUES         3       3       3          2       7           3   \n",
       "CARDIN (%)         0.34    0.34    0.34       0.22    0.79        0.34   \n",
       "\n",
       "                 alive alone  \n",
       "DATA_TYPE       object  bool  \n",
       "NOT-NULL COUNT     891   891  \n",
       "MISSINGS (%)       0.0   0.0  \n",
       "UNIQUE_VALUES        2     2  \n",
       "CARDIN (%)        0.22  0.22  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df_extra(titanic_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: tipifica_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable' (variable names) and 'tipo_sugerido' (suggested type based on cardinality and percentage).\n",
    "        It provides the column names and their suggested type classification based on cardinality thresholds.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "    \n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested types\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add the column name and its classification to the respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "    \n",
    "    # Create a DataFrame with the column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "        \n",
    "    # Return the final DataFrame with classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables_extra(df, umbral_categoria, umbral_continua, *, show_cardinality=False, show_percentage=False):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "    show_cardinality : bool, optional (default=False)\n",
    "        If True, includes the cardinality (number of unique values) of each column in the output DataFrame.\n",
    "    show_percentage : bool, optional (default=False)\n",
    "        If True, includes the percentage of unique values (cardinality relative to the total number of rows) of each column in the output DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable', 'tipo_sugerido', and optionally 'cardinalidad' and '%_cardinalidad'based on the input flags (show_cardinality and show_percentage).\n",
    "        The DataFrame provides the column names and their suggested type classification.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "\n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested type\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "    \n",
    "    # Lists to store cardinality and percentage, if required\n",
    "    if show_cardinality:\n",
    "        cardinality_list = []\n",
    "    if show_percentage:\n",
    "        percentage_list = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add column name and its classification to their respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "        \n",
    "        # If show_cardinality is True, store the cardinality value\n",
    "        if show_cardinality:\n",
    "            cardinality_list.append(cardinality)\n",
    "        # If show_percentage is True, store the percentage cardinality, rounded to 2 decimal places\n",
    "        if show_percentage:\n",
    "            percentage_list.append(round(percentage_cardinality, 2))\n",
    "    \n",
    "    # Create a DataFrame with column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "    \n",
    "    # Insert additional columns based on the flags: show_cardinality and show_percentage\n",
    "    if show_cardinality and show_percentage:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "        df_type.insert(2, '%_cardinalidad', percentage_list)\n",
    "    elif show_cardinality:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "    elif show_percentage:\n",
    "        df_type.insert(1, '%_cardinalidad', percentage_list)\n",
    "\n",
    "    # Return the final DataFrame with the classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_variable</th>\n",
       "      <th>cardinalidad</th>\n",
       "      <th>%_cardinalidad</th>\n",
       "      <th>tipo_sugerido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaraia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pclass</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaraia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>88</td>\n",
       "      <td>9.88</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parch</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fare</td>\n",
       "      <td>248</td>\n",
       "      <td>27.83</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embarked</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>who</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adult_male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaraia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deck</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alive</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaraia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alone</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaraia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nombre_variable  cardinalidad  %_cardinalidad      tipo_sugerido\n",
       "0         survived             2            0.22           Binaraia\n",
       "1           pclass             3            0.34  Numerica Discreta\n",
       "2              sex             2            0.22           Binaraia\n",
       "3              age            88            9.88  Numerica Continua\n",
       "4            sibsp             7            0.79  Numerica Discreta\n",
       "5            parch             7            0.79  Numerica Discreta\n",
       "6             fare           248           27.83  Numerica Continua\n",
       "7         embarked             3            0.34  Numerica Discreta\n",
       "8            class             3            0.34  Numerica Discreta\n",
       "9              who             3            0.34  Numerica Discreta\n",
       "10      adult_male             2            0.22           Binaraia\n",
       "11            deck             7            0.79  Numerica Discreta\n",
       "12     embark_town             3            0.34  Numerica Discreta\n",
       "13           alive             2            0.22           Binaraia\n",
       "14           alone             2            0.22           Binaraia"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipifica_variables_extra(titanic_df, 3, 9.6, show_cardinality = True, show_percentage = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, pvalue=None, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the correlation between numeric columns in a DataFrame and a specified target column.\n",
    "    Stores and returns a list of columns that have an absolute Pearson correlation stat greater than a specified threshold ('umbral_corr').\n",
    "    If a p-value is specified (pvalue) then this is used to check correlations for statistical signifcance and this is accounted for in column selection.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    target_col (str): Target column to correlate with numeric columns.\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for the correlation test.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation test.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    list ('features_num'): A list of columns that have correlated with target column above the specified threshold 'umbral_corr'\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"First arguement must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #2. check target_col is in df\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"The column '{target_col}' is not in the the specified DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #3. check target_col is numeric and continuous (high cardinality)\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The column '{target_col}' must be a continuous numeric variable with high cardinality. \\nCheck the 'card' value.\")\n",
    "        return None\n",
    "    \n",
    "    # Check umbral_corr is float between 0 and 1 (and not (0 <= umbral_corr => 1)\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print(\"'umbral_corr' must be a number between 0 and 1.\")\n",
    "        return None\n",
    "    \n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "        \n",
    "    #2. Initialize features list to store selected numeric features\n",
    "    features_num = []\n",
    "\n",
    "    #3. Loop over all numeric columns in the dataframe\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html\n",
    "    for col in df.select_dtypes(include=[float, int]).columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "\n",
    "        # Calculate pearsonr corr stat and p_value\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "        # Check corr stat is greater than 'umbral_corr'\n",
    "        # Convert to absolute value to avoid problems with negative correlations\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None:\n",
    "                features_num.append(col)\n",
    "            elif p_val <= 1 - pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the selected numeric columns list 'features_num'\n",
    "    return features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col=\"\", card=20, columns=[], umbral_corr=0, pvalue=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates pair plots for numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    Pair plots are generated in maximum 5x5 grids.\n",
    "    If specific numeric columns are not specified the function will filter the numeric columns in the DataFrame based on\n",
    "    a specified correlation threshold ('umbral_corr') and optionally a p-value significance level.\n",
    "    Checks the threshold conditions of specified columns and offers options to remove if columns are not valid or continue\n",
    "    anyway.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe containing data.\n",
    "    target_col (str): The target column to correlate with other numeric columns. Must be numeric continuous variable with high cardinality.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for correlation testing if numeric columns are not specified.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation testing if numeric columns are not specified.\n",
    "\n",
    "    Returns:\n",
    "    list ('columns'): List of columns used for generating the pair plots\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    #2. Check target_col is in DataFrame, and is numeric and continuous (high cardinality)\n",
    "    if target_col not in df.columns or not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "        return None\n",
    "    \n",
    "    #3. Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "\n",
    "    # If no numeric columns are specified, get columns using function 'get_features_num_regression()' based on 'umbral_corr' and 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "    else:\n",
    "        valid_cols = [] # Create empty list to store columns that meet threshold conditions\n",
    "        for col in columns: # Loop through columns in columns list\n",
    "            if col == target_col:\n",
    "                continue # Skip the target column itself as already been checked for validity\n",
    "\n",
    "            # Calculate pearsonr corr stat and p_value between column and target column\n",
    "            corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "            # Check corr stat and p-value meet specified thresholds\n",
    "            if abs(corr) > umbral_corr:\n",
    "                if pvalue is None or p_val <= pvalue:\n",
    "                    valid_cols.append(col) # add column to valid_cols list if it meets both thresholds\n",
    "                else:\n",
    "                    # Warn that column does not meet the required p-value significance level\n",
    "                    print(f\"'{col}' did not meet the p-value signifcance level\")\n",
    "                    # Ask if you want to remove the column or continue anyway\n",
    "                    question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "\n",
    "                    if question == 'continue': \n",
    "                        valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                    else:\n",
    "                        print(f\"'{col}' was removed from columns list\")\n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                # Warn that column does not meet the required correlation threshold\n",
    "                print(f\"'{col}' did not meet the correlation threshold of {umbral_corr}.\")\n",
    "                # Ask if you want to remove the column or continue anyway\n",
    "                question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "                if question == 'continue':\n",
    "                    valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                else:\n",
    "                    print(f\"'{col}' was removed from columns list\")\n",
    "                    continue\n",
    "        \n",
    "        if valid_cols: # Check there are still valid columns left in valid_cols\n",
    "            columns = valid_cols # Sets columns to valid_columns after checks and warnings\n",
    "        else:\n",
    "            columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "\n",
    "    columns = [col for col in columns if col != target_col] # Make sure target is not in columns list to plot\n",
    "    print(f\"columns selected for pair plot analysis were: {columns}\")\n",
    "    \n",
    "    # Generate pair plots in max 5x5 grids\n",
    "    for i in range(0, len(columns), 4):\n",
    "        sns.pairplot(df, vars=[target_col] + columns[i:i + 4])\n",
    "        plt.show()\n",
    "\n",
    "    # Return the selected numeric columns list 'columns'\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway, mannwhitneyu\n",
    "# possibile addition? --> see comment marked ???\n",
    "def get_features_cat_regression(df, target_col, pvalue=0.05, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the significance of relationship between categorical columns and a specified numeric target column in a DataFrame.\n",
    "    Uses ANOVA for multi-cats or Mann_whitney U for binary-cats\n",
    "    Stores and returns a list of columns that have show a significant relationship with target column based on spcifed (optionally) pvalue.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data\n",
    "    target_col (str): Numeric target column for testing relationship with categorical columns\n",
    "    pvalue (float, optional, Default=0.05): Significance level (between 0 and 1) for statistical test evaluation.\n",
    "    card (int): Cardinality threshold (based on unique values) to determine if a column should be considered categorical.\n",
    "\n",
    "    Returns:\n",
    "    list ('categorical_features'): A list of categorical columns that have a significant relationship with target column based on pvalue arguement.\n",
    "    \"\"\"\n",
    "    # Carry out input data checks\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    #2. Check target column in DataFrame\n",
    "    if not target_col in df.columns:\n",
    "        print(f\"The target column ('{target_col}') must be in the DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Check target column is numeric and has sufficiently high cardinality\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "\n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be a 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "    \n",
    "    # Create empty list to store columns considered to have statistically significant relationship with target column\n",
    "    categorical_features = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        if col == target_col: # Skip target column itself\n",
    "            continue\n",
    "        \n",
    "        # Check the cardinality of column to decide if categorical or not\n",
    "        if len(df[col].unique()) <= card: #??? Could we add if 'df[col].dtype == 'object' to this if?\n",
    "            # If categorical and binary perform Mann-Whitney U test\n",
    "            if df[col].nunique() == 2:\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            \n",
    "            else:\n",
    "                # If categorical with more than 2 groups, perform ANOVA test\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "            # Check p-val against pvalue arguement to see if significance threshold is met\n",
    "            if p_val <= pvalue:\n",
    "                categorical_features.append(col) # Add to categorical_features list if deemed significant\n",
    "\n",
    "    # Return list of categorical features\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función recibe un dataframe, una argumento \"target_col\" con valor por defecto \"\", una lista de strings (\"columns\") cuyo valor por defecto es la lista vacía, un argumento (\"pvalue\") con valor 0.05 por defecto y un argumento \"with_individual_plot\" a False.\n",
    "\n",
    "Si la lista no está vacía, la función pintará los histogramas agrupados de la variable \"target_col\" para cada uno de los valores de las variables categóricas incluidas en columns que cumplan que su test de relación con \"target_col\" es significatio para el nivel 1-pvalue de significación estadística. La función devolverá los valores de \"columns\" que cumplan con las condiciones anteriores. \n",
    "\n",
    "Si la lista está vacía, entonces la función igualará \"columns\" a las variables numéricas del dataframe y se comportará como se describe en el párrafo anterior.\n",
    "\n",
    "De igual manera que en la función descrita anteriormente deberá hacer un check de los valores de entrada y comportarse como se describe en el último párrafo de la función `get_features_cat_regression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
