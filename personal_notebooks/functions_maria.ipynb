{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Mar√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "cities_df = pd.read_csv('../data/california_cities.csv')\n",
    "inmo_df = pd.read_csv('../data/ejemplo_housing.csv')\n",
    "flights_df = pd.read_csv('../data/dataset_viajes_jun23.csv')\n",
    "customers_df = pd.read_csv('../data/Marketing-Customer-Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_basic(df): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values and cardinality (percentage of unique values).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values and cardinality for each column of the input DataFrame.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    }).T\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_extra(df, count = False): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values, cardinality (percentage of unique values), and optionally, the count of non-null values.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    count : bool, optional\n",
    "        If True, includes the count of non-null values in each column (default is False).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values, cardinality, and optionally, the count of non-null values for each column.\n",
    "    \n",
    "    Raises:\n",
    "    -------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    })\n",
    "    \n",
    "    # Optionally add the count of non-null values and rearrange the columns\n",
    "    if count:\n",
    "        not_null_count = df.notna().sum()\n",
    "        df_summary.insert(1, 'NOT-NULL COUNT', not_null_count)\n",
    "\n",
    "    return df_summary.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE        int64  int64  object  float64  int64  int64  float64   \n",
       "MISSINGS (%)       0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES        2      3       2       88      7      7      248   \n",
       "CARDIN (%)        0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "              embarked   class     who adult_male    deck embark_town   alive  \\\n",
       "DATA_TYPE       object  object  object       bool  object      object  object   \n",
       "MISSINGS (%)      0.22     0.0     0.0        0.0   77.22        0.22     0.0   \n",
       "UNIQUE_VALUES        3       3       3          2       7           3       2   \n",
       "CARDIN (%)        0.34    0.34    0.34       0.22    0.79        0.34    0.22   \n",
       "\n",
       "              alone  \n",
       "DATA_TYPE      bool  \n",
       "MISSINGS (%)    0.0  \n",
       "UNIQUE_VALUES     2  \n",
       "CARDIN (%)     0.22  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df_basic(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT-NULL COUNT</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE         int64  int64  object  float64  int64  int64  float64   \n",
       "NOT-NULL COUNT      891    891     891      714    891    891      891   \n",
       "MISSINGS (%)        0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES         2      3       2       88      7      7      248   \n",
       "CARDIN (%)         0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "               embarked   class     who adult_male    deck embark_town  \\\n",
       "DATA_TYPE        object  object  object       bool  object      object   \n",
       "NOT-NULL COUNT      889     891     891        891     203         889   \n",
       "MISSINGS (%)       0.22     0.0     0.0        0.0   77.22        0.22   \n",
       "UNIQUE_VALUES         3       3       3          2       7           3   \n",
       "CARDIN (%)         0.34    0.34    0.34       0.22    0.79        0.34   \n",
       "\n",
       "                 alive alone  \n",
       "DATA_TYPE       object  bool  \n",
       "NOT-NULL COUNT     891   891  \n",
       "MISSINGS (%)       0.0   0.0  \n",
       "UNIQUE_VALUES        2     2  \n",
       "CARDIN (%)        0.22  0.22  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df_extra(titanic_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: tipifica_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    types_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality for each column\n",
    "        cardinality = df[col].nunique()\n",
    "        # Calculate percentage cardinality for each column\n",
    "        percentage_cardinality = cardinality / len(df) * 100\n",
    "\n",
    "        # Classify each variable based on cardinality and percentage cardinality\n",
    "        # Binary variables: 2 unique values\n",
    "        if cardinality == 2:\n",
    "            tipo = 'Binaraia'\n",
    "        # Categorical variables: unique values less than or equal to 'umbral_categoria'\n",
    "        elif cardinality <= umbral_categoria:\n",
    "            tipo = 'Categorica'\n",
    "        # Classify numeric variables: unique values greater than 'umbral_categoria'\n",
    "        elif cardinality > umbral_categoria:\n",
    "            # Numeric continuous: percentage cardinality greater than or equal to 'umbral_continua'\n",
    "            if percentage_cardinality >= umbral_continua:\n",
    "                tipo = 'Numerica Continua'\n",
    "            # Numeric discrete: percentage cardinality below 'umbral_continua'\n",
    "            else:\n",
    "                tipo = 'Numerica Discreta'\n",
    "\n",
    "        # Store proposed variable types in the dictionary 'types_dict' with column names as keys\n",
    "        types_dict[col] = tipo\n",
    "\n",
    "    # Create a DataFrame from the 'types_dict' dictionary with two columns: 'nombre_variable' and 'tipo_sugerido'\n",
    "    df_temp = pd.DataFrame(types_dict.items(), columns=['nombre_variable', 'tipo_sugerido'])\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, pvalue=None, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the correlation between numeric columns in a DataFrame and a specified target column.\n",
    "    Stores and returns a list of columns that have an absolute Pearson correlation stat greater than a specified threshold ('umbral_corr').\n",
    "    If a p-value is specified (pvalue) then this is used to check correlations for statistical signifcance and this is accounted for in column selection.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    target_col (str): Target column to correlate with numeric columns.\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for the correlation test.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation test.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    list ('features_num'): A list of columns that have correlated with target column above the specified threshold 'umbral_corr'\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"First arguement must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #2. check target_col is in df\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"The column '{target_col}' is not in the the specified DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #3. check target_col is numeric and continuous (high cardinality)\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The column '{target_col}' must be a continuous numeric variable with high cardinality. \\nCheck the 'card' value.\")\n",
    "        return None\n",
    "    \n",
    "    # Check umbral_corr is float between 0 and 1 (and not (0 <= umbral_corr => 1)\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print(\"'umbral_corr' must be a number between 0 and 1.\")\n",
    "        return None\n",
    "    \n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "        \n",
    "    #2. Initialize features list to store selected numeric features\n",
    "    features_num = []\n",
    "\n",
    "    #3. Loop over all numeric columns in the dataframe\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html\n",
    "    for col in df.select_dtypes(include=[float, int]).columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "\n",
    "        # Calculate pearsonr corr stat and p_value\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "        # Check corr stat is greater than 'umbral_corr'\n",
    "        # Convert to absolute value to avoid problems with negative correlations\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None:\n",
    "                features_num.append(col)\n",
    "            elif p_val <= 1 - pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the selected numeric columns list 'features_num'\n",
    "    return features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col=\"\", card=20, columns=[], umbral_corr=0, pvalue=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates pair plots for numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    Pair plots are generated in maximum 5x5 grids.\n",
    "    If specific numeric columns are not specified the function will filter the numeric columns in the DataFrame based on\n",
    "    a specified correlation threshold ('umbral_corr') and optionally a p-value significance level.\n",
    "    Checks the threshold conditions of specified columns and offers options to remove if columns are not valid or continue\n",
    "    anyway.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe containing data.\n",
    "    target_col (str): The target column to correlate with other numeric columns. Must be numeric continuous variable with high cardinality.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for correlation testing if numeric columns are not specified.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation testing if numeric columns are not specified.\n",
    "\n",
    "    Returns:\n",
    "    list ('columns'): List of columns used for generating the pair plots\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    #2. Check target_col is in DataFrame, and is numeric and continuous (high cardinality)\n",
    "    if target_col not in df.columns or not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "        return None\n",
    "    \n",
    "    #3. Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "\n",
    "    # If no numeric columns are specified, get columns using function 'get_features_num_regression()' based on 'umbral_corr' and 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "    else:\n",
    "        valid_cols = [] # Create empty list to store columns that meet threshold conditions\n",
    "        for col in columns: # Loop through columns in columns list\n",
    "            if col == target_col:\n",
    "                continue # Skip the target column itself as already been checked for validity\n",
    "\n",
    "            # Calculate pearsonr corr stat and p_value between column and target column\n",
    "            corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "            # Check corr stat and p-value meet specified thresholds\n",
    "            if abs(corr) > umbral_corr:\n",
    "                if pvalue is None or p_val <= pvalue:\n",
    "                    valid_cols.append(col) # add column to valid_cols list if it meets both thresholds\n",
    "                else:\n",
    "                    # Warn that column does not meet the required p-value significance level\n",
    "                    print(f\"'{col}' did not meet the p-value signifcance level\")\n",
    "                    # Ask if you want to remove the column or continue anyway\n",
    "                    question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "\n",
    "                    if question == 'continue': \n",
    "                        valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                    else:\n",
    "                        print(f\"'{col}' was removed from columns list\")\n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                # Warn that column does not meet the required correlation threshold\n",
    "                print(f\"'{col}' did not meet the correlation threshold of {umbral_corr}.\")\n",
    "                # Ask if you want to remove the column or continue anyway\n",
    "                question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "                if question == 'continue':\n",
    "                    valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                else:\n",
    "                    print(f\"'{col}' was removed from columns list\")\n",
    "                    continue\n",
    "        \n",
    "        if valid_cols: # Check there are still valid columns left in valid_cols\n",
    "            columns = valid_cols # Sets columns to valid_columns after checks and warnings\n",
    "        else:\n",
    "            columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "\n",
    "    columns = [col for col in columns if col != target_col] # Make sure target is not in columns list to plot\n",
    "    print(f\"columns selected for pair plot analysis were: {columns}\")\n",
    "    \n",
    "    # Generate pair plots in max 5x5 grids\n",
    "    for i in range(0, len(columns), 4):\n",
    "        sns.pairplot(df, vars=[target_col] + columns[i:i + 4])\n",
    "        plt.show()\n",
    "\n",
    "    # Return the selected numeric columns list 'columns'\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway, mannwhitneyu\n",
    "# possibile addition? --> see comment marked ???\n",
    "def get_features_cat_regression(df, target_col, pvalue=0.05, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the significance of relationship between categorical columns and a specified numeric target column in a DataFrame.\n",
    "    Uses ANOVA for multi-cats or Mann_whitney U for binary-cats\n",
    "    Stores and returns a list of columns that have show a significant relationship with target column based on spcifed (optionally) pvalue.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data\n",
    "    target_col (str): Numeric target column for testing relationship with categorical columns\n",
    "    pvalue (float, optional, Default=0.05): Significance level (between 0 and 1) for statistical test evaluation.\n",
    "    card (int): Cardinality threshold (based on unique values) to determine if a column should be considered categorical.\n",
    "\n",
    "    Returns:\n",
    "    list ('categorical_features'): A list of categorical columns that have a significant relationship with target column based on pvalue arguement.\n",
    "    \"\"\"\n",
    "    # Carry out input data checks\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    #2. Check target column in DataFrame\n",
    "    if not target_col in df.columns:\n",
    "        print(f\"The target column ('{target_col}') must be in the DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Check target column is numeric and has sufficiently high cardinality\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "\n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be a 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "    \n",
    "    # Create empty list to store columns considered to have statistically significant relationship with target column\n",
    "    categorical_features = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        if col == target_col: # Skip target column itself\n",
    "            continue\n",
    "        \n",
    "        # Check the cardinality of column to decide if categorical or not\n",
    "        if len(df[col].unique()) <= card: #??? Could we add if 'df[col].dtype == 'object' to this if?\n",
    "            # If categorical and binary perform Mann-Whitney U test\n",
    "            if df[col].nunique() == 2:\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            \n",
    "            else:\n",
    "                # If categorical with more than 2 groups, perform ANOVA test\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "            # Check p-val against pvalue arguement to see if significance threshold is met\n",
    "            if p_val <= pvalue:\n",
    "                categorical_features.append(col) # Add to categorical_features list if deemed significant\n",
    "\n",
    "    # Return list of categorical features\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funci√≥n recibe un dataframe, una argumento \"target_col\" con valor por defecto \"\", una lista de strings (\"columns\") cuyo valor por defecto es la lista vac√≠a, un argumento (\"pvalue\") con valor 0.05 por defecto y un argumento \"with_individual_plot\" a False.\n",
    "\n",
    "Si la lista no est√° vac√≠a, la funci√≥n pintar√° los histogramas agrupados de la variable \"target_col\" para cada uno de los valores de las variables categ√≥ricas incluidas en columns que cumplan que su test de relaci√≥n con \"target_col\" es significatio para el nivel 1-pvalue de significaci√≥n estad√≠stica. La funci√≥n devolver√° los valores de \"columns\" que cumplan con las condiciones anteriores. \n",
    "\n",
    "Si la lista est√° vac√≠a, entonces la funci√≥n igualar√° \"columns\" a las variables num√©ricas del dataframe y se comportar√° como se describe en el p√°rrafo anterior.\n",
    "\n",
    "De igual manera que en la funci√≥n descrita anteriormente deber√° hacer un check de los valores de entrada y comportarse como se describe en el √∫ltimo p√°rrafo de la funci√≥n `get_features_cat_regression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
