{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions María"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "cities_df = pd.read_csv('../data/california_cities.csv')\n",
    "inmo_df = pd.read_csv('../data/ejemplo_housing.csv')\n",
    "flights_df = pd.read_csv('../data/dataset_viajes_jun23.csv')\n",
    "customers_df = pd.read_csv('../data/Marketing-Customer-Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>latd</th>\n",
       "      <th>longd</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>population_total</th>\n",
       "      <th>area_total_sq_mi</th>\n",
       "      <th>area_land_sq_mi</th>\n",
       "      <th>area_water_sq_mi</th>\n",
       "      <th>area_total_km2</th>\n",
       "      <th>area_land_km2</th>\n",
       "      <th>area_water_km2</th>\n",
       "      <th>area_water_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adelanto</td>\n",
       "      <td>34.576111</td>\n",
       "      <td>-117.432778</td>\n",
       "      <td>875.0</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>31765</td>\n",
       "      <td>56.027</td>\n",
       "      <td>56.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>145.107</td>\n",
       "      <td>145.062</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AgouraHills</td>\n",
       "      <td>34.153333</td>\n",
       "      <td>-118.761667</td>\n",
       "      <td>281.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>20330</td>\n",
       "      <td>7.822</td>\n",
       "      <td>7.793</td>\n",
       "      <td>0.029</td>\n",
       "      <td>20.260</td>\n",
       "      <td>20.184</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>37.756111</td>\n",
       "      <td>-122.274444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>75467</td>\n",
       "      <td>22.960</td>\n",
       "      <td>10.611</td>\n",
       "      <td>12.349</td>\n",
       "      <td>59.465</td>\n",
       "      <td>27.482</td>\n",
       "      <td>31.983</td>\n",
       "      <td>53.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Albany</td>\n",
       "      <td>37.886944</td>\n",
       "      <td>-122.297778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18969</td>\n",
       "      <td>5.465</td>\n",
       "      <td>1.788</td>\n",
       "      <td>3.677</td>\n",
       "      <td>14.155</td>\n",
       "      <td>4.632</td>\n",
       "      <td>9.524</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alhambra</td>\n",
       "      <td>34.081944</td>\n",
       "      <td>-118.135000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>83089</td>\n",
       "      <td>7.632</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.766</td>\n",
       "      <td>19.763</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>Yountville</td>\n",
       "      <td>38.403056</td>\n",
       "      <td>-122.362222</td>\n",
       "      <td>30.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2933</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.966</td>\n",
       "      <td>3.966</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>Yreka</td>\n",
       "      <td>41.726667</td>\n",
       "      <td>-122.637500</td>\n",
       "      <td>787.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>7765</td>\n",
       "      <td>10.053</td>\n",
       "      <td>9.980</td>\n",
       "      <td>0.073</td>\n",
       "      <td>26.036</td>\n",
       "      <td>25.847</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>YubaCity</td>\n",
       "      <td>39.134722</td>\n",
       "      <td>-121.626111</td>\n",
       "      <td>18.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64925</td>\n",
       "      <td>14.656</td>\n",
       "      <td>14.578</td>\n",
       "      <td>0.078</td>\n",
       "      <td>37.959</td>\n",
       "      <td>37.758</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>Yucaipa</td>\n",
       "      <td>34.030278</td>\n",
       "      <td>-117.048611</td>\n",
       "      <td>798.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>51367</td>\n",
       "      <td>27.893</td>\n",
       "      <td>27.888</td>\n",
       "      <td>0.005</td>\n",
       "      <td>72.244</td>\n",
       "      <td>72.231</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>YuccaValley</td>\n",
       "      <td>34.133333</td>\n",
       "      <td>-116.416667</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>20700</td>\n",
       "      <td>40.015</td>\n",
       "      <td>40.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>103.639</td>\n",
       "      <td>103.639</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         city       latd       longd  elevation_m  \\\n",
       "0             0     Adelanto  34.576111 -117.432778        875.0   \n",
       "1             1  AgouraHills  34.153333 -118.761667        281.0   \n",
       "2             2      Alameda  37.756111 -122.274444          NaN   \n",
       "3             3       Albany  37.886944 -122.297778          NaN   \n",
       "4             4     Alhambra  34.081944 -118.135000        150.0   \n",
       "..          ...          ...        ...         ...          ...   \n",
       "477         477   Yountville  38.403056 -122.362222         30.0   \n",
       "478         478        Yreka  41.726667 -122.637500        787.0   \n",
       "479         479     YubaCity  39.134722 -121.626111         18.0   \n",
       "480         480      Yucaipa  34.030278 -117.048611        798.0   \n",
       "481         481  YuccaValley  34.133333 -116.416667       1027.0   \n",
       "\n",
       "     elevation_ft  population_total  area_total_sq_mi  area_land_sq_mi  \\\n",
       "0          2871.0             31765            56.027           56.009   \n",
       "1           922.0             20330             7.822            7.793   \n",
       "2            33.0             75467            22.960           10.611   \n",
       "3            43.0             18969             5.465            1.788   \n",
       "4           492.0             83089             7.632            7.631   \n",
       "..            ...               ...               ...              ...   \n",
       "477          98.0              2933             1.531            1.531   \n",
       "478        2582.0              7765            10.053            9.980   \n",
       "479          59.0             64925            14.656           14.578   \n",
       "480        2618.0             51367            27.893           27.888   \n",
       "481        3369.0             20700            40.015           40.015   \n",
       "\n",
       "     area_water_sq_mi  area_total_km2  area_land_km2  area_water_km2  \\\n",
       "0               0.018         145.107        145.062           0.046   \n",
       "1               0.029          20.260         20.184           0.076   \n",
       "2              12.349          59.465         27.482          31.983   \n",
       "3               3.677          14.155          4.632           9.524   \n",
       "4               0.001          19.766         19.763           0.003   \n",
       "..                ...             ...            ...             ...   \n",
       "477             0.000           3.966          3.966           0.000   \n",
       "478             0.073          26.036         25.847           0.188   \n",
       "479             0.078          37.959         37.758           0.201   \n",
       "480             0.005          72.244         72.231           0.013   \n",
       "481             0.000         103.639        103.639           0.000   \n",
       "\n",
       "     area_water_percent  \n",
       "0                  0.03  \n",
       "1                  0.37  \n",
       "2                 53.79  \n",
       "3                 67.28  \n",
       "4                  0.01  \n",
       "..                  ...  \n",
       "477                0.00  \n",
       "478                0.72  \n",
       "479                0.53  \n",
       "480                0.02  \n",
       "481                0.00  \n",
       "\n",
       "[482 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values and cardinality (percentage of unique values).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values and cardinality for each column of the input DataFrame.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    }).T\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_extra(df, count = False): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values, cardinality (percentage of unique values), and optionally, the count of non-null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    count : bool, optional\n",
    "        If True, includes the count of non-null values in each column (default is False).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values, cardinality, and optionally, the count of non-null values for each column.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    })\n",
    "    \n",
    "    # Optionally add the count of non-null values and rearrange the columns\n",
    "    if count:\n",
    "        not_null_count = df.notna().sum()\n",
    "        df_summary.insert(1, 'NOT-NULL COUNT', not_null_count)\n",
    "\n",
    "    return df_summary.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE        int64  int64  object  float64  int64  int64  float64   \n",
       "MISSINGS (%)       0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES        2      3       2       88      7      7      248   \n",
       "CARDIN (%)        0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "              embarked   class     who adult_male    deck embark_town   alive  \\\n",
       "DATA_TYPE       object  object  object       bool  object      object  object   \n",
       "MISSINGS (%)      0.22     0.0     0.0        0.0   77.22        0.22     0.0   \n",
       "UNIQUE_VALUES        3       3       3          2       7           3       2   \n",
       "CARDIN (%)        0.34    0.34    0.34       0.22    0.79        0.34    0.22   \n",
       "\n",
       "              alone  \n",
       "DATA_TYPE      bool  \n",
       "MISSINGS (%)    0.0  \n",
       "UNIQUE_VALUES     2  \n",
       "CARDIN (%)     0.22  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT-NULL COUNT</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE         int64  int64  object  float64  int64  int64  float64   \n",
       "NOT-NULL COUNT      891    891     891      714    891    891      891   \n",
       "MISSINGS (%)        0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES         2      3       2       88      7      7      248   \n",
       "CARDIN (%)         0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "               embarked   class     who adult_male    deck embark_town  \\\n",
       "DATA_TYPE        object  object  object       bool  object      object   \n",
       "NOT-NULL COUNT      889     891     891        891     203         889   \n",
       "MISSINGS (%)       0.22     0.0     0.0        0.0   77.22        0.22   \n",
       "UNIQUE_VALUES         3       3       3          2       7           3   \n",
       "CARDIN (%)         0.34    0.34    0.34       0.22    0.79        0.34   \n",
       "\n",
       "                 alive alone  \n",
       "DATA_TYPE       object  bool  \n",
       "NOT-NULL COUNT     891   891  \n",
       "MISSINGS (%)       0.0   0.0  \n",
       "UNIQUE_VALUES        2     2  \n",
       "CARDIN (%)        0.22  0.22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df_extra(titanic_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: tipifica_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable' (variable names) and 'tipo_sugerido' (suggested type based on cardinality and percentage).\n",
    "        It provides the column names and their suggested type classification based on cardinality thresholds.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "    \n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested types\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add the column name and its classification to the respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "    \n",
    "    # Create a DataFrame with the column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "        \n",
    "    # Return the final DataFrame with classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables_extra(df, umbral_categoria, umbral_continua, *, show_cardinality=False, show_percentage=False):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "    show_cardinality : bool, optional (default=False)\n",
    "        If True, includes the cardinality (number of unique values) of each column in the output DataFrame.\n",
    "    show_percentage : bool, optional (default=False)\n",
    "        If True, includes the percentage of unique values (cardinality relative to the total number of rows) of each column in the output DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable', 'tipo_sugerido', and optionally 'cardinalidad' and '%_cardinalidad'based on the input flags (show_cardinality and show_percentage).\n",
    "        The DataFrame provides the column names and their suggested type classification.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "\n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested type\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "    \n",
    "    # Lists to store cardinality and percentage, if required\n",
    "    if show_cardinality:\n",
    "        cardinality_list = []\n",
    "    if show_percentage:\n",
    "        percentage_list = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add column name and its classification to their respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "        \n",
    "        # If show_cardinality is True, store the cardinality value\n",
    "        if show_cardinality:\n",
    "            cardinality_list.append(cardinality)\n",
    "        # If show_percentage is True, store the percentage cardinality, rounded to 2 decimal places\n",
    "        if show_percentage:\n",
    "            percentage_list.append(round(percentage_cardinality, 2))\n",
    "    \n",
    "    # Create a DataFrame with column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "    \n",
    "    # Insert additional columns based on the flags: show_cardinality and show_percentage\n",
    "    if show_cardinality and show_percentage:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "        df_type.insert(2, '%_cardinalidad', percentage_list)\n",
    "    elif show_cardinality:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "    elif show_percentage:\n",
    "        df_type.insert(1, '%_cardinalidad', percentage_list)\n",
    "\n",
    "    # Return the final DataFrame with the classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_variable</th>\n",
       "      <th>cardinalidad</th>\n",
       "      <th>%_cardinalidad</th>\n",
       "      <th>tipo_sugerido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pclass</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>88</td>\n",
       "      <td>9.88</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parch</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fare</td>\n",
       "      <td>248</td>\n",
       "      <td>27.83</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embarked</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>who</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adult_male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deck</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alive</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alone</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nombre_variable  cardinalidad  %_cardinalidad      tipo_sugerido\n",
       "0         survived             2            0.22            Binaria\n",
       "1           pclass             3            0.34  Numerica Discreta\n",
       "2              sex             2            0.22            Binaria\n",
       "3              age            88            9.88  Numerica Continua\n",
       "4            sibsp             7            0.79  Numerica Discreta\n",
       "5            parch             7            0.79  Numerica Discreta\n",
       "6             fare           248           27.83  Numerica Continua\n",
       "7         embarked             3            0.34  Numerica Discreta\n",
       "8            class             3            0.34  Numerica Discreta\n",
       "9              who             3            0.34  Numerica Discreta\n",
       "10      adult_male             2            0.22            Binaria\n",
       "11            deck             7            0.79  Numerica Discreta\n",
       "12     embark_town             3            0.34  Numerica Discreta\n",
       "13           alive             2            0.22            Binaria\n",
       "14           alone             2            0.22            Binaria"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipifica_variables_extra(titanic_df, 3, 9.6, show_cardinality = True, show_percentage = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, *, pvalue = None, card = 20):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with the 'target_col' exceeds a specified\n",
    "    correlation threshold and, optionally, passes a statistical significance test based on the p-value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame containing the data.\n",
    "    target_col: str\n",
    "        Target column to correlate with other numeric columns.\n",
    "    umbral_corr: float \n",
    "        Correlation threshold for filtering columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        Significance level to filter statistically significant correlations (between 0 and 1).\n",
    "    card: int, float\n",
    "        Minimum cardinality percentage required for 'target_col' to be considered continuous.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num: list\n",
    "        A list of numeric column names whose correlation with 'target_col' exceeds the threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the list of selected numeric features\n",
    "    return features_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression_extra(df, target_col, umbral_corr, *, pvalue = None, card = 20, return_values = False):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with 'target_col' exceeds a specified\n",
    "    correlation threshold (absolute value) and, optionally, passes a statistical significance test based on the p-value.\n",
    "    Optionally, returns detailed information about the correlations and p-values of the filtered features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col : str\n",
    "        The target column name to calculate correlation with other numeric columns.\n",
    "    umbral_corr : float\n",
    "        The correlation threshold to filter columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        The significance level to filter statistically significant correlations (between 0 and 1). Default is None.\n",
    "    card : int, float, optional\n",
    "        The minimum cardinality percentage required for 'target_col' to be considered continuous. Default is 20.\n",
    "    return_values : bool, optional\n",
    "        If True, returns a DataFrame with correlations and p-values for each filtered column. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num : list\n",
    "        A list of column names whose correlation with 'target_col' exceeds the 'umbral_corr' threshold.\n",
    "    all_values : pandas.DataFrame, optional\n",
    "        If `return_values=True`, returns a DataFrame containing the correlation and p-value for each selected feature, \n",
    "        sorted by the correlation in descending order. Columns are named 'corr' and 'p_value'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Initialize dictionary to store all correlations and p-values if return_values is True\n",
    "    if return_values:\n",
    "        all_values = {}\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "                if return_values:\n",
    "                    all_values[col] = {'corr': corr, 'p_value': p_val}\n",
    "    \n",
    "\n",
    "    # Return features_num and, if requested, a DataFrame with correlations and p-values\n",
    "    if return_values:\n",
    "        return features_num, pd.DataFrame(all_values).T.sort_values('corr', ascending = False)\n",
    "    else:\n",
    "        return features_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['parch', 'pclass', 'sibsp', 'survived'],\n",
       "               corr       p_value\n",
       " survived  0.257307  6.120189e-15\n",
       " parch     0.216225  6.915292e-11\n",
       " sibsp     0.159651  1.671256e-06\n",
       " pclass   -0.549500  1.967386e-71)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_num_regression_extra(titanic_df, 'fare', 0, return_values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col = '', columns = [], umbral_corr = 0, pvalue = None):\n",
    "    \"\"\"\n",
    "    Generates pair plots for selected numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    The columns are filtered by a correlation threshold and optionally a p-value significance level. If the columns list is \n",
    "    empty, the numeric columns in the DataFrame are considered. If more than 5 columns are to be plotted, the function splits \n",
    "    them into multiple pair plots, including the target column in each plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col: str \n",
    "        The target column to correlate with other numeric columns. It must be a numeric variable.\n",
    "    columns: list \n",
    "        List of column names to consider for the pair plots. If empty, numeric columns will be automatically selected.\n",
    "    umbral_corr: float \n",
    "        Correlation threshold (default is 0). Only columns with absolute correlation higher than this value will be considered.\n",
    "    pvalue: float, optional\n",
    "        Significance level for the correlation test. Only columns with p-value less than this will be considered. Default is None (no p-value check).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list: \n",
    "        List of columns that meet the correlation and p-value conditions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError('The \"df\" parameter must be a pandas DataFrame.')\n",
    "\n",
    "    # Validate target column\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f'The target column \"{target_col}\" is not present in the DataFrame.')\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise ValueError(f'The target column \"{target_col}\" must be numeric.')\n",
    "\n",
    "    # Validate correlation threshold\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        raise ValueError('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "\n",
    "    # Validate p-value threshold if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            raise ValueError('The \"pvalue\" must be None or a number between 0 and 1.')\n",
    "\n",
    "\n",
    "    # If no columns are provided, automatically select numeric columns from the DataFrame\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df = df, target_col = target_col, umbral_corr = umbral_corr, pvalue = pvalue)\n",
    "\n",
    "    # Filter columns based on correlation and p-value (if provided)\n",
    "    valid_columns = []\n",
    "    for col in columns:\n",
    "        if col == target_col:\n",
    "            continue  # Skip the target column itself\n",
    "\n",
    "        # Calculate Pearson correlation and p-value between the column and the target column\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "        # Check if the correlation meets the threshold\n",
    "        if abs(corr) > umbral_corr:\n",
    "            # Check p-value significance if pvalue is provided\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                valid_columns.append(col)\n",
    "\n",
    "    # If no valid columns remain after filtering, return an empty list\n",
    "    if not valid_columns:\n",
    "        print('No columns meet the correlation and p-value criteria.')\n",
    "        return []\n",
    "\n",
    "    # Ensure the target column is not included in the pairplot columns\n",
    "    valid_columns = [col for col in valid_columns if col != target_col]\n",
    "\n",
    "    # Plot the pair plots in groups of 5 columns (including target_col)\n",
    "    for i in range(0, len(valid_columns), 4):\n",
    "        cols_to_plot = [target_col] + valid_columns[i:i + 4]\n",
    "        sns.pairplot(df, vars = cols_to_plot, hue = target_col)\n",
    "        plt.show()\n",
    "\n",
    "    # Return the list of valid columns\n",
    "    return valid_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_cat_regression(df, target_col, pvalue = 0.05, card = 20):\n",
    "    \"\"\"\n",
    "    Identifies categorical columns in a DataFrame that have a statistically significant relationship with a specified numeric target column.\n",
    "    The function automatically chooses the appropriate test: ANOVA for categorical columns with more than two categories, and Mann-Whitney U for binary categorical columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col: str\n",
    "        The numeric target column used to test the relationship with categorical columns. This must be a numeric continuous variable with high cardinality.\n",
    "    pvalue: float, optional \n",
    "        The significance level (default is 0.05) for statistical tests. Columns with p-values less than this will be considered significant.\n",
    "    card: int, optional \n",
    "        The maximum percentage of unique values a column can have to be considered categorical (default is 20).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    significant_categorical_features: list\n",
    "        A list of categorical columns that have a statistically significant relationship with the target column, based on the specified p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate if the input is a DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The first argument must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    # Validate the target column exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"The target column '{target_col}' must be present in the DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    # Validate the target column has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "\n",
    "    # Validate the pvalue parameter\n",
    "    if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "        print('\"pvalue\" must be a number between 0 and 1.')\n",
    "        return None\n",
    "\n",
    "    # Initialize a list to store categorical features that have a significant relationship with the target column\n",
    "    significant_categorical_features = []\n",
    "    \n",
    "    # Initialize list with categorical features from the dataframe\n",
    "    cat_columns = df.select_dtypes(include = ['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Validate if there are categorical columns\n",
    "    if not cat_columns:\n",
    "        print('No categorical columns found in dataframe.')\n",
    "        return None\n",
    "\n",
    "    # Iterate through the columns of the DataFrame\n",
    "    for col in cat_columns:\n",
    "        unique_values = df[col].unique()\n",
    "\n",
    "        # If the column is binary, use Mann-Whitney U test\n",
    "        if len(unique_values) == 2:\n",
    "            groupA = df[df[col] == unique_values[0]][target_col]\n",
    "            groupB = df[df[col] == unique_values[1]][target_col]\n",
    "\n",
    "            # Perform the Mann-Whitney U test\n",
    "            p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "\n",
    "        else:\n",
    "            # For columns with more than 2 unique values, use ANOVA (F-test)\n",
    "            target_by_groups = [df[df[col] == group][target_col] for group in unique_values]\n",
    "\n",
    "            # Perform the ANOVA test\n",
    "            p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "        # Check if the p-value is below the specified significance threshold\n",
    "        if p_val <= pvalue:\n",
    "            significant_categorical_features.append(col)\n",
    "\n",
    "    # Return the list of significant categorical features\n",
    "    return significant_categorical_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función recibe un dataframe, una argumento \"target_col\" con valor por defecto \"\", una lista de strings (\"columns\") cuyo valor por defecto es la lista vacía, un argumento (\"pvalue\") con valor 0.05 por defecto y un argumento \"with_individual_plot\" a False.\n",
    "\n",
    "Si la lista no está vacía, la función pintará los histogramas agrupados de la variable \"target_col\" para cada uno de los valores de las variables categóricas incluidas en columns que cumplan que su test de relación con \"target_col\" es significatio para el nivel 1-pvalue de significación estadística. La función devolverá los valores de \"columns\" que cumplan con las condiciones anteriores. \n",
    "\n",
    "Si la lista está vacía, entonces la función igualará \"columns\" a las variables numéricas del dataframe y se comportará como se describe en el párrafo anterior.\n",
    "\n",
    "De igual manera que en la función descrita anteriormente deberá hacer un check de los valores de entrada y comportarse como se describe en el último párrafo de la función `get_features_cat_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_cat_regression(df, target_col=\"\", columns=[], pvalue=0.05, with_individual_plot=False, card=20):\n",
    "    \"\"\"\n",
    "    Generates grouped histograms for categorical columns based on their relationship with a specified numeric target column.\n",
    "    If specific categorical columns are not specified, the function will filter the categorical columns in the DataFrame \n",
    "    based on a significance test with the target column.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df (pd.DataFrame): \n",
    "        DataFrame containing the data.\n",
    "    target_col (str): \n",
    "        The target column to plot histograms for, should be numeric.\n",
    "    columns (list of str): \n",
    "        List of categorical columns to consider for histograms. If empty, will use all categorical columns.\n",
    "    pvalue (float, optional, Default=0.05): \n",
    "        Significance level (between 0 and 1) for the statistical test.\n",
    "    with_individual_plot (bool, optional, Default=False): \n",
    "        If True, generates individual histograms for each category.\n",
    "    card (int): \n",
    "        Cardinality threshold for determining if a column is considered categorical.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list (valid_columns): \n",
    "        List of columns that met the significance level.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Carry out input data checks\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('First argument must be a Pandas DataFrame.')\n",
    "    \n",
    "    #2. Check target_col is in DataFrame, and is numeric and continuous (high cardinality)\n",
    "    if target_col not in df.columns or not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        raise TypeError(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "    \n",
    "    #3. Check pvalue is float between 0 and 1\n",
    "    if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "        raise ValueError(\"'pvalue' must be a number between 0 and 1.\")\n",
    "\n",
    "    # If no categorical columns are specified, get columns using function 'get_features_cat_regression()' using specified 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_cat_regression(df=df, target_col=target_col, pvalue=pvalue, card=card)\n",
    "    \n",
    "    # get list of columns and remove target if present to plot histograms\n",
    "    valid_columns = []\n",
    "    for col in columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        \n",
    "        # Check if the column in valid_columns is categorical\n",
    "        if len(df[col].unique()) <= card:\n",
    "            # Perform the significance tests for the column\n",
    "            if df[col].nunique() == 2:\n",
    "                # Perform Mann-Whitney U test if only 2 groups present\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            else:\n",
    "                # Perform ANOVA test if multiple groups in categorical column\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "            \n",
    "            # Check p-value against significance level\n",
    "            if p_val <= pvalue:\n",
    "                valid_columns.append(col)\n",
    "            else:\n",
    "                print(f\"'{col}' did not meet the p-value significance level of {pvalue}.\")\n",
    "        else:\n",
    "            print(f\"'{col}' is not considered categorical based on your specified cardinality.\")\n",
    "    \n",
    "    if not valid_columns:\n",
    "        # Add a print line if no columns are provided and 'get_features_cat_regression' returns no columns based on specified 'pvalue'\n",
    "        print(f'There are no categorical features with significant differences between the means\\nof the groupings in relation to the specified target variable')\n",
    "        return None\n",
    "    \n",
    "    # Plot histograms for valid categorical columns\n",
    "    if not with_individual_plot:\n",
    "        # Calculate number of columns per row\n",
    "        num_cols = min(len(valid_columns), 4) \n",
    "        # Calculate number of rows\n",
    "        num_rows = (len(valid_columns) + num_cols - 1) // num_cols \n",
    "\n",
    "        # Adjust figure size for number of rows\n",
    "        plt.figure(figsize=(16, 5 * num_rows))  \n",
    "\n",
    "        # All histograms on 1 figure\n",
    "        for i, col in enumerate(valid_columns):\n",
    "            plt.subplot(num_rows, num_cols, i + 1) # Logic for number of rows and columns\n",
    "            sns.histplot(data=df, x=target_col, hue=col, element='step') # element='step' made the overlapping of histograms easier to understand visually\n",
    "            plt.title(f'{target_col} by {col}')\n",
    "            plt.xlabel(target_col)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        # Plot histograms individually\n",
    "        for col in valid_columns:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.histplot(data=df, x=target_col, hue=col, element='step')\n",
    "            plt.title(f'Histogram of {target_col} grouped by {col}')\n",
    "            plt.xlabel(target_col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "    \n",
    "    # Return the valid categorical columns\n",
    "    return valid_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_cat_regression(df, target_col = '', columns = [], pvalue = 0.05, with_individual_plot = False):\n",
    "    \"\"\"\n",
    "    Plots histograms of the target column grouped by values of categorical variables that have a statistically significant relationship\n",
    "    with the target column. The function filters the columns based on the provided p-value threshold using statistical tests.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df (pd.DataFrame): \n",
    "        DataFrame containing the data.\n",
    "    target_col (str): \n",
    "        Name of the numeric target column to be used in the analysis. This column must be numeric.\n",
    "    columns (list of str, optional): \n",
    "        List of categorical columns to evaluate. If empty, numeric columns from the DataFrame will be used.\n",
    "    pvalue (float, optional): \n",
    "        Significance level for statistical tests. Only columns with p-values less than this will be considered significant. Default is 0.05.\n",
    "    with_individual_plot (bool, optional): \n",
    "        If True, individual histograms for each significant categorical column will be plotted. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list:\n",
    "        A list of columns that have a statistically significant relationship with the target column based on the p-value threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate if the input is a DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The first argument must be a Pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate if 'target_col' is a valid numeric column\n",
    "    if target_col and (target_col not in df.columns or not pd.api.types.is_numeric_dtype(df[target_col])):\n",
    "        print(f'Error: \"{target_col}\" is not a valid numeric column in the dataframe.')\n",
    "        return None\n",
    "\n",
    "    # Validate 'pvalue' is a valid float\n",
    "    if not isinstance(pvalue, float) or not (0 <= pvalue <= 1):\n",
    "        print('Error: \"pvalue\" should be a float between 0 and 1.')\n",
    "        return None\n",
    "\n",
    "    # Validate 'columns' is a valid list of strings\n",
    "    if not isinstance(columns, list) or not all(isinstance(col, str) for col in columns):\n",
    "        print('Error: \"columns\" should be a list of strings.')\n",
    "        return None\n",
    "\n",
    "    # Validate 'with_individual_plot' is a boolean\n",
    "    if not isinstance(with_individual_plot, bool):\n",
    "        print('Error: \"with_individual_plot\" should be a boolean.')\n",
    "        return None\n",
    "\n",
    "    # If 'columns' is empty, select all numeric columns from the DataFrame\n",
    "    if not columns:\n",
    "        columns = get_features_cat_regression(df, target_col, pvalue)\n",
    "    else:\n",
    "        # Filter columns based on get_features_cat_regression\n",
    "        cat_regression = get_features_cat_regression(df, target_col, pvalue)\n",
    "        selected_columns = list(set(cat_regression) & set(columns))\n",
    "\n",
    "    if not selected_columns:\n",
    "        print('No columns meet the specified conditions for plotting.')\n",
    "        return None\n",
    "\n",
    "    # Plotting\n",
    "    # If with_individual_plot is True, plot each histogram separately\n",
    "    if with_individual_plot:\n",
    "        for col in selected_columns:\n",
    "            plt.figure(figsize = (8, 5))\n",
    "            sns.histplot(data = df, x = col, hue = target_col, kde = True, multiple = 'stack')\n",
    "            plt.title(f'Grouped histogram for {target_col} vs {col}')\n",
    "            plt.show()\n",
    "            \n",
    "    # Default plotting behavior: grouped histograms in subplots\n",
    "    n_plots = len(selected_columns)\n",
    "    n_columns = 3\n",
    "    n_rows = (n_plots // n_columns) + (1 if n_plots % n_columns != 0 else 0)\n",
    "    \n",
    "    fig, axs = plt.subplots(n_rows, 3, figsize = (7 * n_columns, 5 * n_rows))\n",
    "    axs = axs.flatten() if n_plots > 1 else [axs]\n",
    "    \n",
    "    for i, cat_col in enumerate(selected_columns):\n",
    "        sns.histplot(data = df, x = target_col, hue = cat_col, multiple = 'stack', kde = True, ax = axs[i])\n",
    "        plt.title(f'Histogram for {target_col} with {cat_col}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Return the list of selected categorical columns\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/8fjpczhs30b9c9v4f53f5wf80000gn/T/ipykernel_26810/1989686439.py:77: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  p_val = f_oneway(*target_by_groups).pvalue\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'selected_columns' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_features_cat_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitanic_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfare\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 58\u001b[0m, in \u001b[0;36mplot_features_cat_regression\u001b[0;34m(df, target_col, columns, pvalue, with_individual_plot)\u001b[0m\n\u001b[1;32m     55\u001b[0m     cat_regression \u001b[38;5;241m=\u001b[39m get_features_cat_regression(df, target_col, pvalue)\n\u001b[1;32m     56\u001b[0m     selected_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(cat_regression) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mselected_columns\u001b[49m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo columns meet the specified conditions for plotting.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'selected_columns' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "plot_features_cat_regression(titanic_df, 'fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
