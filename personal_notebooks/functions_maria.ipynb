{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions María"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "cities_df = pd.read_csv('../data/california_cities.csv')\n",
    "inmo_df = pd.read_csv('../data/ejemplo_housing.csv')\n",
    "flights_df = pd.read_csv('../data/dataset_viajes_jun23.csv')\n",
    "customers_df = pd.read_csv('../data/Marketing-Customer-Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>city</th>\n",
       "      <th>latd</th>\n",
       "      <th>longd</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>population_total</th>\n",
       "      <th>area_total_sq_mi</th>\n",
       "      <th>area_land_sq_mi</th>\n",
       "      <th>area_water_sq_mi</th>\n",
       "      <th>area_total_km2</th>\n",
       "      <th>area_land_km2</th>\n",
       "      <th>area_water_km2</th>\n",
       "      <th>area_water_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Adelanto</td>\n",
       "      <td>34.576111</td>\n",
       "      <td>-117.432778</td>\n",
       "      <td>875.0</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>31765</td>\n",
       "      <td>56.027</td>\n",
       "      <td>56.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>145.107</td>\n",
       "      <td>145.062</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AgouraHills</td>\n",
       "      <td>34.153333</td>\n",
       "      <td>-118.761667</td>\n",
       "      <td>281.0</td>\n",
       "      <td>922.0</td>\n",
       "      <td>20330</td>\n",
       "      <td>7.822</td>\n",
       "      <td>7.793</td>\n",
       "      <td>0.029</td>\n",
       "      <td>20.260</td>\n",
       "      <td>20.184</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>37.756111</td>\n",
       "      <td>-122.274444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>75467</td>\n",
       "      <td>22.960</td>\n",
       "      <td>10.611</td>\n",
       "      <td>12.349</td>\n",
       "      <td>59.465</td>\n",
       "      <td>27.482</td>\n",
       "      <td>31.983</td>\n",
       "      <td>53.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Albany</td>\n",
       "      <td>37.886944</td>\n",
       "      <td>-122.297778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>18969</td>\n",
       "      <td>5.465</td>\n",
       "      <td>1.788</td>\n",
       "      <td>3.677</td>\n",
       "      <td>14.155</td>\n",
       "      <td>4.632</td>\n",
       "      <td>9.524</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alhambra</td>\n",
       "      <td>34.081944</td>\n",
       "      <td>-118.135000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>83089</td>\n",
       "      <td>7.632</td>\n",
       "      <td>7.631</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.766</td>\n",
       "      <td>19.763</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>Yountville</td>\n",
       "      <td>38.403056</td>\n",
       "      <td>-122.362222</td>\n",
       "      <td>30.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2933</td>\n",
       "      <td>1.531</td>\n",
       "      <td>1.531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.966</td>\n",
       "      <td>3.966</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>478</td>\n",
       "      <td>Yreka</td>\n",
       "      <td>41.726667</td>\n",
       "      <td>-122.637500</td>\n",
       "      <td>787.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>7765</td>\n",
       "      <td>10.053</td>\n",
       "      <td>9.980</td>\n",
       "      <td>0.073</td>\n",
       "      <td>26.036</td>\n",
       "      <td>25.847</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>YubaCity</td>\n",
       "      <td>39.134722</td>\n",
       "      <td>-121.626111</td>\n",
       "      <td>18.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>64925</td>\n",
       "      <td>14.656</td>\n",
       "      <td>14.578</td>\n",
       "      <td>0.078</td>\n",
       "      <td>37.959</td>\n",
       "      <td>37.758</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>480</td>\n",
       "      <td>Yucaipa</td>\n",
       "      <td>34.030278</td>\n",
       "      <td>-117.048611</td>\n",
       "      <td>798.0</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>51367</td>\n",
       "      <td>27.893</td>\n",
       "      <td>27.888</td>\n",
       "      <td>0.005</td>\n",
       "      <td>72.244</td>\n",
       "      <td>72.231</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>YuccaValley</td>\n",
       "      <td>34.133333</td>\n",
       "      <td>-116.416667</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>20700</td>\n",
       "      <td>40.015</td>\n",
       "      <td>40.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>103.639</td>\n",
       "      <td>103.639</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         city       latd       longd  elevation_m  \\\n",
       "0             0     Adelanto  34.576111 -117.432778        875.0   \n",
       "1             1  AgouraHills  34.153333 -118.761667        281.0   \n",
       "2             2      Alameda  37.756111 -122.274444          NaN   \n",
       "3             3       Albany  37.886944 -122.297778          NaN   \n",
       "4             4     Alhambra  34.081944 -118.135000        150.0   \n",
       "..          ...          ...        ...         ...          ...   \n",
       "477         477   Yountville  38.403056 -122.362222         30.0   \n",
       "478         478        Yreka  41.726667 -122.637500        787.0   \n",
       "479         479     YubaCity  39.134722 -121.626111         18.0   \n",
       "480         480      Yucaipa  34.030278 -117.048611        798.0   \n",
       "481         481  YuccaValley  34.133333 -116.416667       1027.0   \n",
       "\n",
       "     elevation_ft  population_total  area_total_sq_mi  area_land_sq_mi  \\\n",
       "0          2871.0             31765            56.027           56.009   \n",
       "1           922.0             20330             7.822            7.793   \n",
       "2            33.0             75467            22.960           10.611   \n",
       "3            43.0             18969             5.465            1.788   \n",
       "4           492.0             83089             7.632            7.631   \n",
       "..            ...               ...               ...              ...   \n",
       "477          98.0              2933             1.531            1.531   \n",
       "478        2582.0              7765            10.053            9.980   \n",
       "479          59.0             64925            14.656           14.578   \n",
       "480        2618.0             51367            27.893           27.888   \n",
       "481        3369.0             20700            40.015           40.015   \n",
       "\n",
       "     area_water_sq_mi  area_total_km2  area_land_km2  area_water_km2  \\\n",
       "0               0.018         145.107        145.062           0.046   \n",
       "1               0.029          20.260         20.184           0.076   \n",
       "2              12.349          59.465         27.482          31.983   \n",
       "3               3.677          14.155          4.632           9.524   \n",
       "4               0.001          19.766         19.763           0.003   \n",
       "..                ...             ...            ...             ...   \n",
       "477             0.000           3.966          3.966           0.000   \n",
       "478             0.073          26.036         25.847           0.188   \n",
       "479             0.078          37.959         37.758           0.201   \n",
       "480             0.005          72.244         72.231           0.013   \n",
       "481             0.000         103.639        103.639           0.000   \n",
       "\n",
       "     area_water_percent  \n",
       "0                  0.03  \n",
       "1                  0.37  \n",
       "2                 53.79  \n",
       "3                 67.28  \n",
       "4                  0.01  \n",
       "..                  ...  \n",
       "477                0.00  \n",
       "478                0.72  \n",
       "479                0.53  \n",
       "480                0.02  \n",
       "481                0.00  \n",
       "\n",
       "[482 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values and cardinality (percentage of unique values).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values and cardinality for each column of the input DataFrame.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    }).T\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_extra(df, count = False): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values, cardinality (percentage of unique values), and optionally, the count of non-null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    count : bool, optional\n",
    "        If True, includes the count of non-null values in each column (default is False).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values, cardinality, and optionally, the count of non-null values for each column.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    })\n",
    "    \n",
    "    # Optionally add the count of non-null values and rearrange the columns\n",
    "    if count:\n",
    "        not_null_count = df.notna().sum()\n",
    "        df_summary.insert(1, 'NOT-NULL COUNT', not_null_count)\n",
    "\n",
    "    return df_summary.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE        int64  int64  object  float64  int64  int64  float64   \n",
       "MISSINGS (%)       0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES        2      3       2       88      7      7      248   \n",
       "CARDIN (%)        0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "              embarked   class     who adult_male    deck embark_town   alive  \\\n",
       "DATA_TYPE       object  object  object       bool  object      object  object   \n",
       "MISSINGS (%)      0.22     0.0     0.0        0.0   77.22        0.22     0.0   \n",
       "UNIQUE_VALUES        3       3       3          2       7           3       2   \n",
       "CARDIN (%)        0.34    0.34    0.34       0.22    0.79        0.34    0.22   \n",
       "\n",
       "              alone  \n",
       "DATA_TYPE      bool  \n",
       "MISSINGS (%)    0.0  \n",
       "UNIQUE_VALUES     2  \n",
       "CARDIN (%)     0.22  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOT-NULL COUNT</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>203</td>\n",
       "      <td>889</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSINGS (%)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUE_VALUES</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARDIN (%)</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>27.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               survived pclass     sex      age  sibsp  parch     fare  \\\n",
       "DATA_TYPE         int64  int64  object  float64  int64  int64  float64   \n",
       "NOT-NULL COUNT      891    891     891      714    891    891      891   \n",
       "MISSINGS (%)        0.0    0.0     0.0    19.87    0.0    0.0      0.0   \n",
       "UNIQUE_VALUES         2      3       2       88      7      7      248   \n",
       "CARDIN (%)         0.22   0.34    0.22     9.88   0.79   0.79    27.83   \n",
       "\n",
       "               embarked   class     who adult_male    deck embark_town  \\\n",
       "DATA_TYPE        object  object  object       bool  object      object   \n",
       "NOT-NULL COUNT      889     891     891        891     203         889   \n",
       "MISSINGS (%)       0.22     0.0     0.0        0.0   77.22        0.22   \n",
       "UNIQUE_VALUES         3       3       3          2       7           3   \n",
       "CARDIN (%)         0.34    0.34    0.34       0.22    0.79        0.34   \n",
       "\n",
       "                 alive alone  \n",
       "DATA_TYPE       object  bool  \n",
       "NOT-NULL COUNT     891   891  \n",
       "MISSINGS (%)       0.0   0.0  \n",
       "UNIQUE_VALUES        2     2  \n",
       "CARDIN (%)        0.22  0.22  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_df_extra(titanic_df, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: tipifica_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable' (variable names) and 'tipo_sugerido' (suggested type based on cardinality and percentage).\n",
    "        It provides the column names and their suggested type classification based on cardinality thresholds.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "    \n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested types\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add the column name and its classification to the respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "    \n",
    "    # Create a DataFrame with the column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "        \n",
    "    # Return the final DataFrame with classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables_extra(df, umbral_categoria, umbral_continua, *, show_cardinality=False, show_percentage=False):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "    show_cardinality : bool, optional (default=False)\n",
    "        If True, includes the cardinality (number of unique values) of each column in the output DataFrame.\n",
    "    show_percentage : bool, optional (default=False)\n",
    "        If True, includes the percentage of unique values (cardinality relative to the total number of rows) of each column in the output DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable', 'tipo_sugerido', and optionally 'cardinalidad' and '%_cardinalidad'based on the input flags (show_cardinality and show_percentage).\n",
    "        The DataFrame provides the column names and their suggested type classification.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, int):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, float):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "\n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested type\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "    \n",
    "    # Lists to store cardinality and percentage, if required\n",
    "    if show_cardinality:\n",
    "        cardinality_list = []\n",
    "    if show_percentage:\n",
    "        percentage_list = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add column name and its classification to their respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "        \n",
    "        # If show_cardinality is True, store the cardinality value\n",
    "        if show_cardinality:\n",
    "            cardinality_list.append(cardinality)\n",
    "        # If show_percentage is True, store the percentage cardinality, rounded to 2 decimal places\n",
    "        if show_percentage:\n",
    "            percentage_list.append(round(percentage_cardinality, 2))\n",
    "    \n",
    "    # Create a DataFrame with column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "    \n",
    "    # Insert additional columns based on the flags: show_cardinality and show_percentage\n",
    "    if show_cardinality and show_percentage:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "        df_type.insert(2, '%_cardinalidad', percentage_list)\n",
    "    elif show_cardinality:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "    elif show_percentage:\n",
    "        df_type.insert(1, '%_cardinalidad', percentage_list)\n",
    "\n",
    "    # Return the final DataFrame with the classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_variable</th>\n",
       "      <th>cardinalidad</th>\n",
       "      <th>%_cardinalidad</th>\n",
       "      <th>tipo_sugerido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pclass</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>88</td>\n",
       "      <td>9.88</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sibsp</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parch</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fare</td>\n",
       "      <td>248</td>\n",
       "      <td>27.83</td>\n",
       "      <td>Numerica Continua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embarked</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>who</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adult_male</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>deck</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>embark_town</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>Numerica Discreta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alive</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alone</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Binaria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nombre_variable  cardinalidad  %_cardinalidad      tipo_sugerido\n",
       "0         survived             2            0.22            Binaria\n",
       "1           pclass             3            0.34  Numerica Discreta\n",
       "2              sex             2            0.22            Binaria\n",
       "3              age            88            9.88  Numerica Continua\n",
       "4            sibsp             7            0.79  Numerica Discreta\n",
       "5            parch             7            0.79  Numerica Discreta\n",
       "6             fare           248           27.83  Numerica Continua\n",
       "7         embarked             3            0.34  Numerica Discreta\n",
       "8            class             3            0.34  Numerica Discreta\n",
       "9              who             3            0.34  Numerica Discreta\n",
       "10      adult_male             2            0.22            Binaria\n",
       "11            deck             7            0.79  Numerica Discreta\n",
       "12     embark_town             3            0.34  Numerica Discreta\n",
       "13           alive             2            0.22            Binaria\n",
       "14           alone             2            0.22            Binaria"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipifica_variables_extra(titanic_df, 3, 9.6, show_cardinality = True, show_percentage = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewed: get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, *, pvalue = None, card = 20):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with the 'target_col' exceeds a specified\n",
    "    correlation threshold and, optionally, passes a statistical significance test based on the p-value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame containing the data.\n",
    "    target_col: str\n",
    "        Target column to correlate with other numeric columns.\n",
    "    umbral_corr: float \n",
    "        Correlation threshold for filtering columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        Significance level to filter statistically significant correlations (between 0 and 1).\n",
    "    card: int, float\n",
    "        Minimum cardinality required for 'target_col' to be considered continuous.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num: list\n",
    "        A list of numeric column names whose correlation with 'target_col' exceeds the threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the list of selected numeric features\n",
    "    return features_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression_extra(df, target_col, umbral_corr, *, pvalue = None, card = 20, return_values = False):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with 'target_col' exceeds a specified\n",
    "    correlation threshold (absolute value) and, optionally, passes a statistical significance test based on the p-value.\n",
    "    Optionally, returns detailed information about the correlations and p-values of the filtered features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col : str\n",
    "        The target column name to calculate correlation with other numeric columns.\n",
    "    umbral_corr : float\n",
    "        The correlation threshold to filter columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        The significance level to filter statistically significant correlations (between 0 and 1). Default is None.\n",
    "    card : int, float, optional\n",
    "        The minimum cardinality required for 'target_col' to be considered continuous. Default is 20.\n",
    "    return_values : bool, optional\n",
    "        If True, returns a DataFrame with correlations and p-values for each filtered column. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num : list\n",
    "        A list of column names whose correlation with 'target_col' exceeds the 'umbral_corr' threshold.\n",
    "    all_values : pandas.DataFrame, optional\n",
    "        If `return_values=True`, returns a DataFrame containing the correlation and p-value for each selected feature, \n",
    "        sorted by the correlation in descending order. Columns are named 'corr' and 'p_value'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Initialize dictionary to store all correlations and p-values if return_values is True\n",
    "    if return_values:\n",
    "        all_values = {}\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "                if return_values:\n",
    "                    all_values[col] = {'corr': corr, 'p_value': p_val}\n",
    "    \n",
    "\n",
    "    # Return features_num and, if requested, a DataFrame with correlations and p-values\n",
    "    if return_values:\n",
    "        return features_num, pd.DataFrame(all_values).T.sort_values('corr', ascending = False)\n",
    "    else:\n",
    "        return features_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parch', 'pclass', 'sibsp', 'survived']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_num_regression_extra(titanic_df, 'fare', 0, return_values = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col=\"\", card=20, columns=[], umbral_corr=0, pvalue=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates pair plots for numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    Pair plots are generated in maximum 5x5 grids.\n",
    "    If specific numeric columns are not specified the function will filter the numeric columns in the DataFrame based on\n",
    "    a specified correlation threshold ('umbral_corr') and optionally a p-value significance level.\n",
    "    Checks the threshold conditions of specified columns and offers options to remove if columns are not valid or continue\n",
    "    anyway.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe containing data.\n",
    "    target_col (str): The target column to correlate with other numeric columns. Must be numeric continuous variable with high cardinality.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for correlation testing if numeric columns are not specified.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation testing if numeric columns are not specified.\n",
    "\n",
    "    Returns:\n",
    "    list ('columns'): List of columns used for generating the pair plots\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    #2. Check target_col is in DataFrame, and is numeric and continuous (high cardinality)\n",
    "    if target_col not in df.columns or not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "        return None\n",
    "    \n",
    "    #3. Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "\n",
    "    # If no numeric columns are specified, get columns using function 'get_features_num_regression()' based on 'umbral_corr' and 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "    else:\n",
    "        valid_cols = [] # Create empty list to store columns that meet threshold conditions\n",
    "        for col in columns: # Loop through columns in columns list\n",
    "            if col == target_col:\n",
    "                continue # Skip the target column itself as already been checked for validity\n",
    "\n",
    "            # Calculate pearsonr corr stat and p_value between column and target column\n",
    "            corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "            # Check corr stat and p-value meet specified thresholds\n",
    "            if abs(corr) > umbral_corr:\n",
    "                if pvalue is None or p_val <= pvalue:\n",
    "                    valid_cols.append(col) # add column to valid_cols list if it meets both thresholds\n",
    "                else:\n",
    "                    # Warn that column does not meet the required p-value significance level\n",
    "                    print(f\"'{col}' did not meet the p-value signifcance level\")\n",
    "                    # Ask if you want to remove the column or continue anyway\n",
    "                    question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "\n",
    "                    if question == 'continue': \n",
    "                        valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                    else:\n",
    "                        print(f\"'{col}' was removed from columns list\")\n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                # Warn that column does not meet the required correlation threshold\n",
    "                print(f\"'{col}' did not meet the correlation threshold of {umbral_corr}.\")\n",
    "                # Ask if you want to remove the column or continue anyway\n",
    "                question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "                if question == 'continue':\n",
    "                    valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                else:\n",
    "                    print(f\"'{col}' was removed from columns list\")\n",
    "                    continue\n",
    "        \n",
    "        if valid_cols: # Check there are still valid columns left in valid_cols\n",
    "            columns = valid_cols # Sets columns to valid_columns after checks and warnings\n",
    "        else:\n",
    "            columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "\n",
    "    columns = [col for col in columns if col != target_col] # Make sure target is not in columns list to plot\n",
    "    print(f\"columns selected for pair plot analysis were: {columns}\")\n",
    "    \n",
    "    # Generate pair plots in max 5x5 grids\n",
    "    for i in range(0, len(columns), 4):\n",
    "        sns.pairplot(df, vars=[target_col] + columns[i:i + 4])\n",
    "        plt.show()\n",
    "\n",
    "    # Return the selected numeric columns list 'columns'\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway, mannwhitneyu\n",
    "# possibile addition? --> see comment marked ???\n",
    "def get_features_cat_regression(df, target_col, pvalue=0.05, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the significance of relationship between categorical columns and a specified numeric target column in a DataFrame.\n",
    "    Uses ANOVA for multi-cats or Mann_whitney U for binary-cats\n",
    "    Stores and returns a list of columns that have show a significant relationship with target column based on spcifed (optionally) pvalue.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data\n",
    "    target_col (str): Numeric target column for testing relationship with categorical columns\n",
    "    pvalue (float, optional, Default=0.05): Significance level (between 0 and 1) for statistical test evaluation.\n",
    "    card (int): Cardinality threshold (based on unique values) to determine if a column should be considered categorical.\n",
    "\n",
    "    Returns:\n",
    "    list ('categorical_features'): A list of categorical columns that have a significant relationship with target column based on pvalue arguement.\n",
    "    \"\"\"\n",
    "    # Carry out input data checks\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    #2. Check target column in DataFrame\n",
    "    if not target_col in df.columns:\n",
    "        print(f\"The target column ('{target_col}') must be in the DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Check target column is numeric and has sufficiently high cardinality\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "\n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be a 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "    \n",
    "    # Create empty list to store columns considered to have statistically significant relationship with target column\n",
    "    categorical_features = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        if col == target_col: # Skip target column itself\n",
    "            continue\n",
    "        \n",
    "        # Check the cardinality of column to decide if categorical or not\n",
    "        if len(df[col].unique()) <= card: #??? Could we add if 'df[col].dtype == 'object' to this if?\n",
    "            # If categorical and binary perform Mann-Whitney U test\n",
    "            if df[col].nunique() == 2:\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            \n",
    "            else:\n",
    "                # If categorical with more than 2 groups, perform ANOVA test\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "            # Check p-val against pvalue arguement to see if significance threshold is met\n",
    "            if p_val <= pvalue:\n",
    "                categorical_features.append(col) # Add to categorical_features list if deemed significant\n",
    "\n",
    "    # Return list of categorical features\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función recibe un dataframe, una argumento \"target_col\" con valor por defecto \"\", una lista de strings (\"columns\") cuyo valor por defecto es la lista vacía, un argumento (\"pvalue\") con valor 0.05 por defecto y un argumento \"with_individual_plot\" a False.\n",
    "\n",
    "Si la lista no está vacía, la función pintará los histogramas agrupados de la variable \"target_col\" para cada uno de los valores de las variables categóricas incluidas en columns que cumplan que su test de relación con \"target_col\" es significatio para el nivel 1-pvalue de significación estadística. La función devolverá los valores de \"columns\" que cumplan con las condiciones anteriores. \n",
    "\n",
    "Si la lista está vacía, entonces la función igualará \"columns\" a las variables numéricas del dataframe y se comportará como se describe en el párrafo anterior.\n",
    "\n",
    "De igual manera que en la función descrita anteriormente deberá hacer un check de los valores de entrada y comportarse como se describe en el último párrafo de la función `get_features_cat_regression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
