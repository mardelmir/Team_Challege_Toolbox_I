{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Mar√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df):\n",
    "    data_type = df.dtypes\n",
    "    missings = df.isna().sum()/len(df) * 100\n",
    "    unique_values = df.nunique()\n",
    "    cardin = unique_values / len(df) * 100\n",
    "    \n",
    "    df_temp = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': round(cardin, 2)\n",
    "    })\n",
    "\n",
    "    df_temp = df_temp.T\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: tipifica_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    types_dict = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality for each column\n",
    "        cardinality = df[col].nunique()\n",
    "        # Calculate percentage cardinality for each column\n",
    "        percentage_cardinality = cardinality / len(df) * 100\n",
    "\n",
    "        # Classify each variable based on cardinality and percentage cardinality\n",
    "        # Binary variables: 2 unique values\n",
    "        if cardinality == 2:\n",
    "            tipo = 'Binaraia'\n",
    "        # Categorical variables: unique values less than or equal to 'umbral_categoria'\n",
    "        elif cardinality <= umbral_categoria:\n",
    "            tipo = 'Categorica'\n",
    "        # Classify numeric variables: unique values greater than 'umbral_categoria'\n",
    "        elif cardinality > umbral_categoria:\n",
    "            # Numeric continuous: percentage cardinality greater than or equal to 'umbral_continua'\n",
    "            if percentage_cardinality >= umbral_continua:\n",
    "                tipo = 'Numerica Continua'\n",
    "            # Numeric discrete: percentage cardinality below 'umbral_continua'\n",
    "            else:\n",
    "                tipo = 'Numerica Discreta'\n",
    "\n",
    "        # Store proposed variable types in the dictionary 'types_dict' with column names as keys\n",
    "        types_dict[col] = tipo\n",
    "\n",
    "    # Create a DataFrame from the 'types_dict' dictionary with two columns: 'nombre_variable' and 'tipo_sugerido'\n",
    "    df_temp = pd.DataFrame(types_dict.items(), columns=['nombre_variable', 'tipo_sugerido'])\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return df_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, pvalue=None, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the correlation between numeric columns in a DataFrame and a specified target column.\n",
    "    Stores and returns a list of columns that have an absolute Pearson correlation stat greater than a specified threshold ('umbral_corr').\n",
    "    If a p-value is specified (pvalue) then this is used to check correlations for statistical signifcance and this is accounted for in column selection.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    target_col (str): Target column to correlate with numeric columns.\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for the correlation test.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation test.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    list ('features_num'): A list of columns that have correlated with target column above the specified threshold 'umbral_corr'\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"First arguement must be a Pandas DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #2. check target_col is in df\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"The column '{target_col}' is not in the the specified DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    #3. check target_col is numeric and continuous (high cardinality)\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.api.types.is_numeric_dtype.html\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The column '{target_col}' must be a continuous numeric variable with high cardinality. \\nCheck the 'card' value.\")\n",
    "        return None\n",
    "    \n",
    "    # Check umbral_corr is float between 0 and 1 (and not (0 <= umbral_corr => 1)\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print(\"'umbral_corr' must be a number between 0 and 1.\")\n",
    "        return None\n",
    "    \n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "        \n",
    "    #2. Initialize features list to store selected numeric features\n",
    "    features_num = []\n",
    "\n",
    "    #3. Loop over all numeric columns in the dataframe\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html\n",
    "    for col in df.select_dtypes(include=[float, int]).columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "\n",
    "        # Calculate pearsonr corr stat and p_value\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "        # Check corr stat is greater than 'umbral_corr'\n",
    "        # Convert to absolute value to avoid problems with negative correlations\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None:\n",
    "                features_num.append(col)\n",
    "            elif p_val <= 1 - pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the selected numeric columns list 'features_num'\n",
    "    return features_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col=\"\", card=20, columns=[], umbral_corr=0, pvalue=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates pair plots for numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    Pair plots are generated in maximum 5x5 grids.\n",
    "    If specific numeric columns are not specified the function will filter the numeric columns in the DataFrame based on\n",
    "    a specified correlation threshold ('umbral_corr') and optionally a p-value significance level.\n",
    "    Checks the threshold conditions of specified columns and offers options to remove if columns are not valid or continue\n",
    "    anyway.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Dataframe containing data.\n",
    "    target_col (str): The target column to correlate with other numeric columns. Must be numeric continuous variable with high cardinality.\n",
    "    card (int): Cardinality threshold checks for sufficient unique values in 'target_col'\n",
    "    umbral_corr (float): Correlation threshold (between 0 and 1) for correlation testing if numeric columns are not specified.\n",
    "    pvalue (float, optional, Defaul=None): Signifance level (between 0 and 1) for the correlation testing if numeric columns are not specified.\n",
    "\n",
    "    Returns:\n",
    "    list ('columns'): List of columns used for generating the pair plots\n",
    "    \"\"\"\n",
    "\n",
    "    # First carry out checks to prevent errors\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    #2. Check target_col is in DataFrame, and is numeric and continuous (high cardinality)\n",
    "    if target_col not in df.columns or not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "        return None\n",
    "    \n",
    "    #3. Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "\n",
    "    # If no numeric columns are specified, get columns using function 'get_features_num_regression()' based on 'umbral_corr' and 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "    else:\n",
    "        valid_cols = [] # Create empty list to store columns that meet threshold conditions\n",
    "        for col in columns: # Loop through columns in columns list\n",
    "            if col == target_col:\n",
    "                continue # Skip the target column itself as already been checked for validity\n",
    "\n",
    "            # Calculate pearsonr corr stat and p_value between column and target column\n",
    "            corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "            # Check corr stat and p-value meet specified thresholds\n",
    "            if abs(corr) > umbral_corr:\n",
    "                if pvalue is None or p_val <= pvalue:\n",
    "                    valid_cols.append(col) # add column to valid_cols list if it meets both thresholds\n",
    "                else:\n",
    "                    # Warn that column does not meet the required p-value significance level\n",
    "                    print(f\"'{col}' did not meet the p-value signifcance level\")\n",
    "                    # Ask if you want to remove the column or continue anyway\n",
    "                    question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "\n",
    "                    if question == 'continue': \n",
    "                        valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                    else:\n",
    "                        print(f\"'{col}' was removed from columns list\")\n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                # Warn that column does not meet the required correlation threshold\n",
    "                print(f\"'{col}' did not meet the correlation threshold of {umbral_corr}.\")\n",
    "                # Ask if you want to remove the column or continue anyway\n",
    "                question = input(f\"Do you want to remove '{col}' from the columns list or continue anyway? Type 'remove' or 'continue'\").strip().lower()\n",
    "                if question == 'continue':\n",
    "                    valid_cols.append(col) # adds column to valid_cols list if user types continue\n",
    "                else:\n",
    "                    print(f\"'{col}' was removed from columns list\")\n",
    "                    continue\n",
    "        \n",
    "        if valid_cols: # Check there are still valid columns left in valid_cols\n",
    "            columns = valid_cols # Sets columns to valid_columns after checks and warnings\n",
    "        else:\n",
    "            columns = get_features_num_regression(df=df, target_col=target_col, umbral_corr=umbral_corr, pvalue=pvalue)\n",
    "\n",
    "    columns = [col for col in columns if col != target_col] # Make sure target is not in columns list to plot\n",
    "    print(f\"columns selected for pair plot analysis were: {columns}\")\n",
    "    \n",
    "    # Generate pair plots in max 5x5 grids\n",
    "    for i in range(0, len(columns), 4):\n",
    "        sns.pairplot(df, vars=[target_col] + columns[i:i + 4])\n",
    "        plt.show()\n",
    "\n",
    "    # Return the selected numeric columns list 'columns'\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway, mannwhitneyu\n",
    "# possibile addition? --> see comment marked ???\n",
    "def get_features_cat_regression(df, target_col, pvalue=0.05, card=20):\n",
    "    \"\"\"\n",
    "    Identifies and evaluates the significance of relationship between categorical columns and a specified numeric target column in a DataFrame.\n",
    "    Uses ANOVA for multi-cats or Mann_whitney U for binary-cats\n",
    "    Stores and returns a list of columns that have show a significant relationship with target column based on spcifed (optionally) pvalue.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data\n",
    "    target_col (str): Numeric target column for testing relationship with categorical columns\n",
    "    pvalue (float, optional, Default=0.05): Significance level (between 0 and 1) for statistical test evaluation.\n",
    "    card (int): Cardinality threshold (based on unique values) to determine if a column should be considered categorical.\n",
    "\n",
    "    Returns:\n",
    "    list ('categorical_features'): A list of categorical columns that have a significant relationship with target column based on pvalue arguement.\n",
    "    \"\"\"\n",
    "    # Carry out input data checks\n",
    "    #1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('First arguement must be a Pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    #2. Check target column in DataFrame\n",
    "    if not target_col in df.columns:\n",
    "        print(f\"The target column ('{target_col}') must be in the DataFrame.\")\n",
    "        return None\n",
    "    \n",
    "    # Check target column is numeric and has sufficiently high cardinality\n",
    "    if not (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() > card):\n",
    "        print(f\"The target column ('{target_col}') must be a numeric continuous variable with high cardinality.\\nCheck 'card' value\")\n",
    "\n",
    "    # Check pvalue is float between 0 and 1 (and not (0 <= pvalue => 1)\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print(\"'pvalue' must be a 'None' or a number between 0 and 1.\")\n",
    "            return None\n",
    "    \n",
    "    # Create empty list to store columns considered to have statistically significant relationship with target column\n",
    "    categorical_features = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        if col == target_col: # Skip target column itself\n",
    "            continue\n",
    "        \n",
    "        # Check the cardinality of column to decide if categorical or not\n",
    "        if len(df[col].unique()) <= card: #??? Could we add if 'df[col].dtype == 'object' to this if?\n",
    "            # If categorical and binary perform Mann-Whitney U test\n",
    "            if df[col].nunique() == 2:\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            \n",
    "            else:\n",
    "                # If categorical with more than 2 groups, perform ANOVA test\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "            # Check p-val against pvalue arguement to see if significance threshold is met\n",
    "            if p_val <= pvalue:\n",
    "                categorical_features.append(col) # Add to categorical_features list if deemed significant\n",
    "\n",
    "    # Return list of categorical features\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta funci√≥n recibe un dataframe, una argumento \"target_col\" con valor por defecto \"\", una lista de strings (\"columns\") cuyo valor por defecto es la lista vac√≠a, un argumento (\"pvalue\") con valor 0.05 por defecto y un argumento \"with_individual_plot\" a False.\n",
    "\n",
    "Si la lista no est√° vac√≠a, la funci√≥n pintar√° los histogramas agrupados de la variable \"target_col\" para cada uno de los valores de las variables categ√≥ricas incluidas en columns que cumplan que su test de relaci√≥n con \"target_col\" es significatio para el nivel 1-pvalue de significaci√≥n estad√≠stica. La funci√≥n devolver√° los valores de \"columns\" que cumplan con las condiciones anteriores. \n",
    "\n",
    "Si la lista est√° vac√≠a, entonces la funci√≥n igualar√° \"columns\" a las variables num√©ricas del dataframe y se comportar√° como se describe en el p√°rrafo anterior.\n",
    "\n",
    "De igual manera que en la funci√≥n descrita anteriormente deber√° hacer un check de los valores de entrada y comportarse como se describe en el √∫ltimo p√°rrafo de la funci√≥n `get_features_cat_regression`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
