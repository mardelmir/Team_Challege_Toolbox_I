{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr, f_oneway, mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "\n",
    "titanic_df = pd.read_csv('../data/titanic.csv')\n",
    "cities_df = pd.read_csv('../data/california_cities.csv')\n",
    "inmo_df = pd.read_csv('../data/ejemplo_housing.csv')\n",
    "flights_df = pd.read_csv('../data/dataset_viajes_jun23.csv')\n",
    "customers_df = pd.read_csv('../data/Marketing-Customer-Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df(df): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values and cardinality (percentage of unique values).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values and cardinality for each column of the input DataFrame.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    }).T\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_df_extra(df, count = False): \n",
    "    \"\"\"\n",
    "    Generates a summary DataFrame describing the input DataFrame's data types, percentage of missing values, number of unique values, cardinality (percentage of unique values), and optionally, the count of non-null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to be described.\n",
    "    \n",
    "    count : bool, optional\n",
    "        If True, includes the count of non-null values in each column (default is False).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_summary: pd.DataFrame\n",
    "        A DataFrame with a summary of data types, missing values, unique values, cardinality, and optionally, the count of non-null values for each column.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input is not a pandas DataFrame.\n",
    "    \n",
    "    ValueError\n",
    "        If the DataFrame is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate input type\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Input must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    \n",
    "    # Calculate the length of the DataFrame once\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    # Validate DataFrame length to prevent dividing by 0 later on\n",
    "    if num_rows == 0:\n",
    "        raise ValueError('The DataFrame is empty.')\n",
    "    \n",
    "    # Calculate data types, missing values percentage, unique values and cardinality\n",
    "    data_type = df.dtypes\n",
    "    missings = round(df.isna().sum() / num_rows * 100, 2)\n",
    "    unique_values = df.nunique()\n",
    "    cardin = round(unique_values / num_rows * 100, 2)\n",
    "    \n",
    "    # Construct the summary DataFrame\n",
    "    df_summary = pd.DataFrame({\n",
    "        'DATA_TYPE': data_type,\n",
    "        'MISSINGS (%)': missings,\n",
    "        'UNIQUE_VALUES': unique_values,\n",
    "        'CARDIN (%)': cardin\n",
    "    })\n",
    "    \n",
    "    # Optionally add the count of non-null values and rearrange the columns\n",
    "    if count:\n",
    "        not_null_count = df.notna().sum()\n",
    "        df_summary.insert(1, 'NOT-NULL COUNT', not_null_count)\n",
    "\n",
    "    return df_summary.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tipifica_variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables(df, umbral_categoria, umbral_continua):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable' (variable names) and 'tipo_sugerido' (suggested type based on cardinality and percentage).\n",
    "        It provides the column names and their suggested type classification based on cardinality thresholds.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, (int, float)):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, (int, float)):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "    \n",
    "    # Change types if needed\n",
    "    if isinstance(umbral_categoria, float):\n",
    "        umbral_categoria = int(umbral_categoria)\n",
    "    if isinstance(umbral_continua, int):\n",
    "        umbral_categoria = float(umbral_categoria)\n",
    "    \n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested types\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add the column name and its classification to the respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "    \n",
    "    # Create a DataFrame with the column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "        \n",
    "    # Return the final DataFrame with classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tipifica_variables_extra(df, umbral_categoria, umbral_continua, *, show_cardinality=False, show_percentage=False):\n",
    "    \"\"\"\n",
    "    Classifies the columns of a DataFrame based on their cardinality and percentage cardinality.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The input DataFrame whose columns will be classified.\n",
    "    umbral_categoria : int\n",
    "        The threshold for categorical variables. Columns with unique values less than or equal to this threshold will be classified as 'Categorica'.\n",
    "    umbral_continua : float\n",
    "        The threshold for continuous numerical variables, based on the percentage of unique values in the column. \n",
    "        If the percentage of unique values is greater than or equal to this threshold, the column is classified as 'Numerica Continua'.\n",
    "    show_cardinality : bool, optional (default=False)\n",
    "        If True, includes the cardinality (number of unique values) of each column in the output DataFrame.\n",
    "    show_percentage : bool, optional (default=False)\n",
    "        If True, includes the percentage of unique values (cardinality relative to the total number of rows) of each column in the output DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_type : pandas.DataFrame\n",
    "        A DataFrame with columns 'nombre_variable', 'tipo_sugerido', and optionally 'cardinalidad' and '%_cardinalidad'based on the input flags (show_cardinality and show_percentage).\n",
    "        The DataFrame provides the column names and their suggested type classification.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the input `df` is not a pandas DataFrame, or if `umbral_categoria` is not an integer, or `umbral_continua` is not a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f'Parameter df must be a pandas DataFrame, but received {type(df).__name__}.')\n",
    "    if not isinstance(umbral_categoria, (int, float)):\n",
    "        raise TypeError(f'Parameter umbral_categoria must be int, but received {type(umbral_categoria).__name__}.')\n",
    "    if not isinstance(umbral_continua, (int, float)):\n",
    "        raise TypeError(f'Parameter umbral_continua must be float, but received {type(umbral_continua).__name__}.')\n",
    "    \n",
    "    # Change types if needed\n",
    "    if isinstance(umbral_categoria, float):\n",
    "        umbral_categoria = int(umbral_categoria)\n",
    "    if isinstance(umbral_continua, int):\n",
    "        umbral_categoria = float(umbral_categoria)\n",
    "\n",
    "    # Get the number of rows in the DataFrame\n",
    "    num_rows = len(df) \n",
    "    \n",
    "    # Lists to store column names and their suggested type\n",
    "    col_name = []\n",
    "    suggested_type = []\n",
    "    \n",
    "    # Lists to store cardinality and percentage, if required\n",
    "    if show_cardinality:\n",
    "        cardinality_list = []\n",
    "    if show_percentage:\n",
    "        percentage_list = []\n",
    "\n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Calculate cardinality and percentage cardinality\n",
    "        cardinality = df[col].nunique()\n",
    "        percentage_cardinality = cardinality / num_rows * 100\n",
    "        \n",
    "        # Classify the variable based on cardinality and percentage cardinality\n",
    "        if cardinality == 2:\n",
    "            type_classification = 'Binaria'\n",
    "        elif cardinality < umbral_categoria:\n",
    "            type_classification = 'Categorica'\n",
    "        else:\n",
    "            type_classification = 'Numerica Continua' if percentage_cardinality >= umbral_continua else 'Numerica Discreta'\n",
    "        \n",
    "        # Add column name and its classification to their respective lists\n",
    "        col_name.append(col)\n",
    "        suggested_type.append(type_classification)\n",
    "        \n",
    "        # If show_cardinality is True, store the cardinality value\n",
    "        if show_cardinality:\n",
    "            cardinality_list.append(cardinality)\n",
    "        # If show_percentage is True, store the percentage cardinality, rounded to 2 decimal places\n",
    "        if show_percentage:\n",
    "            percentage_list.append(round(percentage_cardinality, 2))\n",
    "    \n",
    "    # Create a DataFrame with column names and their suggested types\n",
    "    df_type = pd.DataFrame({'nombre_variable': col_name, 'tipo_sugerido': suggested_type})\n",
    "    \n",
    "    # Insert additional columns based on the flags: show_cardinality and show_percentage\n",
    "    if show_cardinality and show_percentage:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "        df_type.insert(2, '%_cardinalidad', percentage_list)\n",
    "    elif show_cardinality:\n",
    "        df_type.insert(1, 'cardinalidad', cardinality_list)\n",
    "    elif show_percentage:\n",
    "        df_type.insert(1, '%_cardinalidad', percentage_list)\n",
    "\n",
    "    # Return the final DataFrame with the classifications\n",
    "    return df_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression(df, target_col, umbral_corr, *, pvalue = None, card = 20):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with the 'target_col' exceeds a specified\n",
    "    correlation threshold and, optionally, passes a statistical significance test based on the p-value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame containing the data.\n",
    "    target_col: str\n",
    "        Target column to correlate with other numeric columns.\n",
    "    umbral_corr: float \n",
    "        Correlation threshold for filtering columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        Significance level to filter statistically significant correlations (between 0 and 1).\n",
    "    card: int, float\n",
    "        Minimum cardinality percentage required for 'target_col' to be considered continuous.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num: list\n",
    "        A list of numeric column names whose correlation with 'target_col' exceeds the threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "\n",
    "    # Return the list of selected numeric features\n",
    "    return features_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_regression_extra(df, target_col, umbral_corr, *, pvalue = None, card = 20, return_values = False):\n",
    "    \"\"\"\n",
    "    Identifies numeric columns in a DataFrame whose correlation with 'target_col' exceeds a specified\n",
    "    correlation threshold (absolute value) and, optionally, passes a statistical significance test based on the p-value.\n",
    "    Optionally, returns detailed information about the correlations and p-values of the filtered features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col : str\n",
    "        The target column name to calculate correlation with other numeric columns.\n",
    "    umbral_corr : float\n",
    "        The correlation threshold to filter columns (absolute value between 0 and 1).\n",
    "    pvalue : float, optional\n",
    "        The significance level to filter statistically significant correlations (between 0 and 1). Default is None.\n",
    "    card : int, float, optional\n",
    "        The minimum cardinality percentage required for 'target_col' to be considered continuous. Default is 20.\n",
    "    return_values : bool, optional\n",
    "        If True, returns a DataFrame with correlations and p-values for each filtered column. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features_num : list\n",
    "        A list of column names whose correlation with 'target_col' exceeds the 'umbral_corr' threshold.\n",
    "    all_values : pandas.DataFrame, optional\n",
    "        If `return_values=True`, returns a DataFrame containing the correlation and p-value for each selected feature, \n",
    "        sorted by the correlation in descending order. Columns are named 'corr' and 'p_value'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate the DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The \"df\" parameter must be a pandas DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f'The column \"{target_col}\" is not present in the DataFrame.')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    if not isinstance(card, (int, float)):\n",
    "        print('The \"card\" parameter must be a number (int or float).')\n",
    "        return None\n",
    "    \n",
    "    # Validate target_col has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "    \n",
    "    # Validate umbral_corr is a float between 0 and 1\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        print('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "        return None\n",
    "    \n",
    "    # Validate pvalue is a float between 0 and 1 if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            print('The \"pvalue\" must be \"None\" or a number (float) between 0 and 1.')\n",
    "            return None\n",
    "    \n",
    "    # Select numeric columns excluding the target column\n",
    "    numeric_cols = df.select_dtypes(include = [int, float]).columns.difference([target_col])\n",
    "    \n",
    "    # Initialize the list to store selected features\n",
    "    features_num = []\n",
    "    \n",
    "    # Initialize dictionary to store all correlations and p-values if return_values is True\n",
    "    if return_values:\n",
    "        all_values = {}\n",
    "    \n",
    "    # Calculate correlations and filter by threshold\n",
    "    for col in numeric_cols:\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "        if abs(corr) > umbral_corr:\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                features_num.append(col)\n",
    "                if return_values:\n",
    "                    all_values[col] = {'corr': corr, 'p_value': p_val}\n",
    "    \n",
    "\n",
    "    # Return features_num and, if requested, a DataFrame with correlations and p-values\n",
    "    if return_values:\n",
    "        return features_num, pd.DataFrame(all_values).T.sort_values('corr', ascending = False)\n",
    "    else:\n",
    "        return features_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_features_num_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_regression(df, target_col = '', columns = [], umbral_corr = 0, pvalue = None):\n",
    "    \"\"\"\n",
    "    Generates pair plots for selected numeric columns in a DataFrame based on their correlation with a specified target column.\n",
    "    The columns are filtered by a correlation threshold and optionally a p-value significance level. If the columns list is \n",
    "    empty, the numeric columns in the DataFrame are considered. If more than 5 columns are to be plotted, the function splits \n",
    "    them into multiple pair plots, including the target column in each plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col: str \n",
    "        The target column to correlate with other numeric columns. It must be a numeric variable.\n",
    "    columns: list \n",
    "        List of column names to consider for the pair plots. If empty, numeric columns will be automatically selected.\n",
    "    umbral_corr: float \n",
    "        Correlation threshold (default is 0). Only columns with absolute correlation higher than this value will be considered.\n",
    "    pvalue: float, optional\n",
    "        Significance level for the correlation test. Only columns with p-value less than this will be considered. Default is None (no p-value check).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list: \n",
    "        List of columns that meet the correlation and p-value conditions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate input DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError('The \"df\" parameter must be a pandas DataFrame.')\n",
    "\n",
    "    # Validate target column\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f'The target column \"{target_col}\" is not present in the DataFrame.')\n",
    "    \n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise ValueError(f'The target column \"{target_col}\" must be numeric.')\n",
    "\n",
    "    # Validate correlation threshold\n",
    "    if not isinstance(umbral_corr, (int, float)) or not (0 <= umbral_corr <= 1):\n",
    "        raise ValueError('The \"umbral_corr\" value must be a number between 0 and 1.')\n",
    "\n",
    "    # Validate p-value threshold if provided\n",
    "    if pvalue is not None:\n",
    "        if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "            raise ValueError('The \"pvalue\" must be None or a number between 0 and 1.')\n",
    "\n",
    "\n",
    "    # If no columns are provided, automatically select numeric columns from the DataFrame\n",
    "    if not columns:\n",
    "        columns = get_features_num_regression(df = df, target_col = target_col, umbral_corr = umbral_corr, pvalue = pvalue)\n",
    "\n",
    "    # Filter columns based on correlation and p-value (if provided)\n",
    "    valid_columns = []\n",
    "    for col in columns:\n",
    "        if col == target_col:\n",
    "            continue  # Skip the target column itself\n",
    "\n",
    "        # Calculate Pearson correlation and p-value between the column and the target column\n",
    "        corr, p_val = pearsonr(df[col], df[target_col])\n",
    "\n",
    "        # Check if the correlation meets the threshold\n",
    "        if abs(corr) > umbral_corr:\n",
    "            # Check p-value significance if pvalue is provided\n",
    "            if pvalue is None or p_val <= pvalue:\n",
    "                valid_columns.append(col)\n",
    "\n",
    "    # If no valid columns remain after filtering, return an empty list\n",
    "    if not valid_columns:\n",
    "        print('No columns meet the correlation and p-value criteria.')\n",
    "        return []\n",
    "\n",
    "    # Ensure the target column is not included in the pairplot columns\n",
    "    valid_columns = [col for col in valid_columns if col != target_col]\n",
    "\n",
    "    # Plot the pair plots in groups of 5 columns (including target_col)\n",
    "    for i in range(0, len(valid_columns), 4):\n",
    "        cols_to_plot = [target_col] + valid_columns[i:i + 4]\n",
    "        sns.pairplot(df, vars = cols_to_plot, hue = target_col)\n",
    "        plt.show()\n",
    "\n",
    "    # Return the list of valid columns\n",
    "    return valid_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_cat_regression(df, target_col, pvalue = 0.05, card = 20):\n",
    "    \"\"\"\n",
    "    Identifies categorical columns in a DataFrame that have a statistically significant relationship with a specified numeric target column.\n",
    "    The function automatically chooses the appropriate test: ANOVA for categorical columns with more than two categories, and Mann-Whitney U for binary categorical columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    target_col: str\n",
    "        The numeric target column used to test the relationship with categorical columns. This must be a numeric continuous variable with high cardinality.\n",
    "    pvalue: float, optional \n",
    "        The significance level (default is 0.05) for statistical tests. Columns with p-values less than this will be considered significant.\n",
    "    card: int, optional \n",
    "        The maximum percentage of unique values a column can have to be considered categorical (default is 20).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    significant_categorical_features: list\n",
    "        A list of categorical columns that have a statistically significant relationship with the target column, based on the specified p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate if the input is a DataFrame\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print('The first argument must be a Pandas DataFrame.')\n",
    "        return None\n",
    "\n",
    "    # Validate the target column exists in the DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"The target column '{target_col}' must be present in the DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    # Validate target_col and card are numeric\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        print(f'The column \"{target_col}\" must be numeric.')\n",
    "        return None\n",
    "    \n",
    "    # Validate the target column has high cardinality\n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "\n",
    "    # Validate the pvalue parameter\n",
    "    if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "        print('\"pvalue\" must be a number between 0 and 1.')\n",
    "        return None\n",
    "\n",
    "    # Initialize a list to store categorical features that have a significant relationship with the target column\n",
    "    significant_categorical_features = []\n",
    "    \n",
    "    # Initialize list with categorical features from the dataframe\n",
    "    cat_columns = df.select_dtypes(include = ['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Validate if there are categorical columns\n",
    "    if not cat_columns:\n",
    "        print('No categorical columns found in dataframe.')\n",
    "        return None\n",
    "\n",
    "    # Iterate through the columns of the DataFrame\n",
    "    for col in cat_columns:\n",
    "        unique_values = df[col].unique()\n",
    "\n",
    "        # If the column is binary, use Mann-Whitney U test\n",
    "        if len(unique_values) == 2:\n",
    "            groupA = df[df[col] == unique_values[0]][target_col]\n",
    "            groupB = df[df[col] == unique_values[1]][target_col]\n",
    "\n",
    "            # Perform the Mann-Whitney U test\n",
    "            p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "\n",
    "        else:\n",
    "            # For columns with more than 2 unique values, use ANOVA (F-test)\n",
    "            target_by_groups = [df[df[col] == group][target_col] for group in unique_values]\n",
    "\n",
    "            # Perform the ANOVA test\n",
    "            p_val = f_oneway(*target_by_groups).pvalue\n",
    "\n",
    "        # Check if the p-value is below the specified significance threshold\n",
    "        if p_val <= pvalue:\n",
    "            significant_categorical_features.append(col)\n",
    "\n",
    "    # Return the list of significant categorical features\n",
    "    return significant_categorical_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_features_cat_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_cat_regression(df, target_col=\"\", columns=[], pvalue=0.05, with_individual_plot=False, card=20):\n",
    "    \"\"\"\n",
    "    Generates grouped histograms for categorical columns based on their relationship with a specified numeric target column.\n",
    "    If specific categorical columns are not specified, the function will filter the categorical columns in the DataFrame \n",
    "    based on a significance test with the target column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame containing the data.\n",
    "    target_col: str\n",
    "        The target column to plot histograms for, should be numeric.\n",
    "    columns: list of str\n",
    "        List of categorical columns to consider for histograms. If empty, will use all categorical columns.\n",
    "    pvalue (float, optional, Default=0.05): \n",
    "        Significance level (between 0 and 1) for the statistical test.\n",
    "    with_individual_plot (bool, optional, Default=False): \n",
    "        If True, generates individual histograms for each category.\n",
    "    card (int): \n",
    "        Cardinality threshold for determining if a column is considered categorical.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list: valid_columns\n",
    "        List of columns that met the significance level.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Carry out input data checks\n",
    "    # 1. Check df is a dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "       raise TypeError('First argument must be a Pandas DataFrame.')\n",
    "\n",
    "    # 2. Check target_col is in DataFrame\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f'The target column \"{target_col}\" is not present in the DataFrame.')\n",
    "    \n",
    "    # 3. Check target_col is numeric and continuous (high cardinality)\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise ValueError(f'The target column \"{target_col}\" must be numeric.')\n",
    "    \n",
    "    percentage_card = df[target_col].nunique() * 100\n",
    "    if percentage_card <= card:\n",
    "        print(f'The column \"{target_col}\" does not have sufficient cardinality. More than {card}% of unique values are required.')\n",
    "        return None\n",
    "\n",
    "    # 4. Check pvalue is float between 0 and 1\n",
    "    if not isinstance(pvalue, (int, float)) or not (0 <= pvalue <= 1):\n",
    "        raise ValueError(\"'pvalue' must be a number between 0 and 1.\")\n",
    "\n",
    "    \n",
    "    # If no categorical columns are specified, get columns using function 'get_features_cat_regression()' using specified 'pvalue'\n",
    "    if not columns:\n",
    "        columns = get_features_cat_regression(df = df, target_col = target_col, pvalue = pvalue, card = card)\n",
    "    \n",
    "    # Get list of columns and remove target if present to plot histograms\n",
    "    valid_columns = []\n",
    "    for col in columns:\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        \n",
    "        # Check if the column in valid_columns is categorical\n",
    "        if len(df[col].unique()) <= card:\n",
    "            # Perform the significance tests for the column\n",
    "            if df[col].nunique() == 2:\n",
    "                # Perform Mann-Whitney U test if only 2 groups present\n",
    "                groupA = df[df[col] == df[col].unique()[0]][target_col]\n",
    "                groupB = df[df[col] == df[col].unique()[1]][target_col]\n",
    "                p_val = mannwhitneyu(groupA, groupB).pvalue\n",
    "            else:\n",
    "                # Perform ANOVA test if multiple groups in categorical column\n",
    "                groups = df[col].unique()\n",
    "                target_by_groups = [df[df[col] == group][target_col] for group in groups]\n",
    "                p_val = f_oneway(*target_by_groups).pvalue\n",
    "            \n",
    "            # Check p-value against significance level\n",
    "            if p_val <= pvalue:\n",
    "                valid_columns.append(col)\n",
    "            else:\n",
    "                print(f\"'{col}' did not meet the p-value significance level of {pvalue}.\")\n",
    "        else:\n",
    "            print(f\"'{col}' is not considered categorical based on your specified cardinality.\")\n",
    "    \n",
    "    if not valid_columns:\n",
    "        # Add a print line if no columns are provided and 'get_features_cat_regression' returns no columns based on specified 'pvalue'\n",
    "        print(f'There are no categorical features with significant differences between the means\\nof the groupings in relation to the specified target variable')\n",
    "        return None\n",
    "    \n",
    "    # Plot histograms for valid categorical columns\n",
    "    if not with_individual_plot:\n",
    "        # Calculate number of columns per row\n",
    "        num_cols = min(len(valid_columns), 4) \n",
    "        # Calculate number of rows\n",
    "        num_rows = (len(valid_columns) + num_cols - 1) // num_cols \n",
    "\n",
    "        # Adjust figure size for number of rows\n",
    "        plt.figure(figsize = (16, 5 * num_rows))  \n",
    "\n",
    "        # All histograms on 1 figure\n",
    "        for i, col in enumerate(valid_columns):\n",
    "            plt.subplot(num_rows, num_cols, i + 1) # Logic for number of rows and columns\n",
    "            sns.histplot(data = df, x = target_col, hue = col, element = 'step') # element='step' made the overlapping of histograms easier to understand visually\n",
    "            plt.title(f'{target_col} by {col}')\n",
    "            plt.xlabel(target_col)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        # Plot histograms individually\n",
    "        for col in valid_columns:\n",
    "            plt.figure(figsize = (12, 6))\n",
    "            sns.histplot(data = df, x = target_col, hue = col, element = 'step')\n",
    "            plt.title(f'Histogram of {target_col} grouped by {col}')\n",
    "            plt.xlabel(target_col)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.show()\n",
    "    \n",
    "    # Return the valid categorical columns\n",
    "    return valid_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
